{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yolo-Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('onetoohot.csv', low_memory=False)\n",
    "bool_columns_list = [col for col in df if col != 'Amount']\n",
    "# Define your features (X) and target (y) from the DataFrame\n",
    "X = df[bool_columns_list]\n",
    "y = df['Amount']\n",
    "\n",
    "# Splitting the dataset into training and test sets (as you've done)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Further split the training set into a new training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Converting to PyTorch tensors and moving to the specified device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Creating datasets and dataloaders for training, validation, and test sets\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_data = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=750, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=750, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=750, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.dropout1 = nn.Dropout(0.2)  # First dropout layer\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.dropout2 = nn.Dropout(0.2)  # Second dropout layer\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.dropout3 = nn.Dropout(0.2)  # Third dropout layer\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.dropout4 = nn.Dropout(0.2)  # Fourth dropout layer\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.dropout5 = nn.Dropout(0.2)  # Fifth dropout layer\n",
    "        self.fc6 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.relu(self.fc5(x))\n",
    "        x = self.dropout5(x)\n",
    "        x = self.fc6(x)  # Apply the last linear layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = RegressionModel(X_train_tensor.shape[1]).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.005, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "\n",
    "# Define a lambda function for learning rate decay\n",
    "def lr_lambda(epoch):\n",
    "    initial_lr = 0.05\n",
    "    final_lr = 0.001\n",
    "    max_epochs = 20000\n",
    "    decay_rate = (final_lr / initial_lr) ** (1 / max_epochs)\n",
    "    return decay_rate ** epoch\n",
    "scheduler = LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000, Validation R2 Score: 0.4162722125085949\n",
      "Epoch 2/20000, Validation R2 Score: 0.4169566072594558\n",
      "Epoch 3/20000, Validation R2 Score: 0.4112554875617893\n",
      "Epoch 4/20000, Validation R2 Score: 0.4211707273037957\n",
      "Epoch 5/20000, Validation R2 Score: 0.3417786956773181\n",
      "Epoch 6/20000, Validation R2 Score: 0.39125387340528983\n",
      "Epoch 7/20000, Validation R2 Score: 0.4153126541596779\n",
      "Epoch 8/20000, Validation R2 Score: 0.4166197253334656\n",
      "Epoch 9/20000, Validation R2 Score: 0.4206587765682882\n",
      "Epoch 10/20000, Validation R2 Score: 0.4047123863254881\n",
      "Epoch 11/20000, Validation R2 Score: 0.41526349047334576\n",
      "Epoch 12/20000, Validation R2 Score: 0.4174787497178817\n",
      "Epoch 13/20000, Validation R2 Score: 0.4157603558401336\n",
      "Epoch 14/20000, Validation R2 Score: 0.4178495888470194\n",
      "Epoch 15/20000, Validation R2 Score: 0.4165321716687391\n",
      "Epoch 16/20000, Validation R2 Score: 0.4157339797179539\n",
      "Epoch 17/20000, Validation R2 Score: 0.4101346480572833\n",
      "Epoch 18/20000, Validation R2 Score: 0.4143593095339074\n",
      "Epoch 19/20000, Validation R2 Score: 0.4152602358478713\n",
      "Epoch 20/20000, Validation R2 Score: 0.41254541653818555\n",
      "Epoch 21/20000, Validation R2 Score: 0.4136386695163665\n",
      "Epoch 22/20000, Validation R2 Score: 0.4170355648489401\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      9\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     11\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move data to the device\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Clear the gradients of all optimized tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_co_py_inlamning2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_co_py_inlamning2\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_co_py_inlamning2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_co_py_inlamning2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_co_py_inlamning2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_co_py_inlamning2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_co_py_inlamning2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_co_py_inlamning2\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "# Optimizer: Adam with specified parameters and a learning rate of 0.001\n",
    "\n",
    "n_epochs = 20000\n",
    "early_stop_threshold = 0.85\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)  # Move data to the device\n",
    "        \n",
    "        # Clear the gradients of all optimized tensors\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(output.view(-1), target)\n",
    "        \n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # Update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            val_predictions.extend(outputs.view(-1).cpu().numpy())\n",
    "            val_targets.extend(y.cpu().numpy())\n",
    "        \n",
    "        val_r2_score = r2_score(val_targets, val_predictions)\n",
    "        print(f'Epoch {epoch+1}/{n_epochs}, Validation R2 Score: {val_r2_score}')\n",
    "\n",
    "        if val_r2_score >= early_stop_threshold:\n",
    "            print(f\"Early stopping at epoch {epoch+1} with R2 Score: {val_r2_score}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 142.04791259765625\n",
      "RMSE: 206.29165649414062\n",
      "R2 Score: 0.4258465895680672\n",
      "MAPE: inf\n",
      "Adjusted R2 Score: 0.42048319010729496\n",
      "---------First 10 Predictions---------\n",
      "Actual/Predicted: 599.0/706.3789672851562\n",
      "Abs Error: 107.37896728515625\n",
      "Rel Error: 17.93%\n",
      "Actual/Predicted: 435.0/433.2632751464844\n",
      "Abs Error: 1.736724853515625\n",
      "Rel Error: 0.40%\n",
      "Actual/Predicted: 1523.0/1104.230712890625\n",
      "Abs Error: 418.769287109375\n",
      "Rel Error: 27.50%\n",
      "Actual/Predicted: 648.5614624023438/652.218994140625\n",
      "Abs Error: 3.65753173828125\n",
      "Rel Error: 0.56%\n",
      "Actual/Predicted: 845.0/1000.3237915039062\n",
      "Abs Error: 155.32379150390625\n",
      "Rel Error: 18.38%\n",
      "Actual/Predicted: 376.0/461.2226257324219\n",
      "Abs Error: 85.22262573242188\n",
      "Rel Error: 22.67%\n",
      "Actual/Predicted: 416.0/405.9302978515625\n",
      "Abs Error: 10.0697021484375\n",
      "Rel Error: 2.42%\n",
      "Actual/Predicted: 899.0/726.4105224609375\n",
      "Abs Error: 172.5894775390625\n",
      "Rel Error: 19.20%\n",
      "Actual/Predicted: 648.5614624023438/618.3818359375\n",
      "Abs Error: 30.17962646484375\n",
      "Rel Error: 4.65%\n",
      "Actual/Predicted: 951.4299926757812/848.5962524414062\n",
      "Abs Error: 102.833740234375\n",
      "Rel Error: 10.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tono\\AppData\\Local\\Temp\\ipykernel_22660\\3384580297.py:26: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y_test_np - predictions_np) / y_test_np)) * 100\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model in detail\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor).view(-1)\n",
    "    \n",
    "    # Convert tensors to numpy arrays for compatibility with sklearn metrics\n",
    "    y_test_np = y_test_tensor.cpu().numpy()\n",
    "    predictions_np = predictions.cpu().numpy()\n",
    "\n",
    "    # Calculating MAE\n",
    "    mae = mean_absolute_error(y_test_np, predictions_np)\n",
    "    print(f'MAE: {mae}')\n",
    "\n",
    "    # RMSE (already calculated)\n",
    "    mse = criterion(predictions, y_test_tensor)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    print(f'RMSE: {rmse.item()}')\n",
    "\n",
    "    # R2 Score (already calculated)\n",
    "    r2 = r2_score(y_test_np, predictions_np)\n",
    "    print(f'R2 Score: {r2}')\n",
    "\n",
    "    # Calculating MAPE\n",
    "    mape = np.mean(np.abs((y_test_np - predictions_np) / y_test_np)) * 100\n",
    "    print(f'MAPE: {mape}')\n",
    "\n",
    "    # Adjusted R2 (for multiple regression models)\n",
    "    n = len(y_test_np) # Number of samples\n",
    "    p = X_test_tensor.shape[1] # Number of independent variables\n",
    "    adjusted_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "    print(f'Adjusted R2 Score: {adjusted_r2}')\n",
    "\n",
    "    print(\"---------First 10 Predictions---------\")\n",
    "    for actual, predicted in zip(y_test_np[:10], predictions_np[:10]):\n",
    "        absolute_error = np.abs(actual - predicted)\n",
    "        relative_error = (absolute_error / actual) * 100 if actual != 0 else float('inf')\n",
    "        print(f\"Actual/Predicted: {actual}/{predicted}\")\n",
    "        print(f\"Abs Error: {absolute_error}\")\n",
    "        print(f\"Rel Error: {relative_error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "#torch.save(model, 'Amazon.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLBIA_comp_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
