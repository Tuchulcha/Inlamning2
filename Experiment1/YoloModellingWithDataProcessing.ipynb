{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from joblib import dump\n",
    "import geohash2 as geohash\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from csv file\n",
    "df = pd.read_csv('AmazonDataSales.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                     0\n",
       "Order ID                  0\n",
       "Date                      0\n",
       "Status                    0\n",
       "Fulfilment                0\n",
       "Sales Channel             0\n",
       "ship-service-level        0\n",
       "Style                     0\n",
       "SKU                       0\n",
       "Category                  0\n",
       "Size                      0\n",
       "ASIN                      0\n",
       "Courier Status         6872\n",
       "Qty                       0\n",
       "currency               7795\n",
       "Amount                 7795\n",
       "ship-city                33\n",
       "ship-state               33\n",
       "ship-postal-code         33\n",
       "ship-country             33\n",
       "promotion-ids         49153\n",
       "B2B                       0\n",
       "fulfilled-by          89698\n",
       "Unnamed: 22           49050\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'promotion-ids', 'fulfilled-by', 'Unnamed: 22' columns\n",
    "df = df.drop(['promotion-ids', 'fulfilled-by', 'Unnamed: 22', 'currency'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                   int64\n",
       "Order ID               object\n",
       "Date                   object\n",
       "Status                 object\n",
       "Fulfilment             object\n",
       "Sales Channel          object\n",
       "ship-service-level     object\n",
       "Style                  object\n",
       "SKU                    object\n",
       "Category               object\n",
       "Size                   object\n",
       "ASIN                   object\n",
       "Courier Status         object\n",
       "Qty                     int64\n",
       "Amount                float64\n",
       "ship-city              object\n",
       "ship-state             object\n",
       "ship-postal-code      float64\n",
       "ship-country           object\n",
       "B2B                      bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing 'Courier Status' with \"Unknown\"\n",
    "# df['Courier Status'].fillna('Unknown', inplace=True) Seems like inplace=True is being disbanded\n",
    "df['Courier Status'] = df['Courier Status'].fillna('Unknown')\n",
    "# Fill missing 'Amount' with mean\n",
    "df['Amount'] = df['Amount'].fillna(value=df['Amount'].mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Qty and Amount: 0.044359066469949894\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore connection between 'Category', 'Size', 'Qty' in relation to 'Amount'\n",
    "\n",
    "\n",
    "# Compute the correlation between 'Qty' and 'Amount'\n",
    "correlation = df['Qty'].corr(df['Amount'])\n",
    "print(\"Correlation between Qty and Amount:\", correlation)\n",
    "\n",
    "# Visualize the relationship with a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['Qty'], df['Amount'])\n",
    "plt.xlabel('Qty')\n",
    "plt.ylabel('Amount')\n",
    "plt.title('Scatter Plot between Qty and Amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                 128975\n",
      "Order ID              120378\n",
      "Date                      91\n",
      "Status                    13\n",
      "Fulfilment                 2\n",
      "Sales Channel              2\n",
      "ship-service-level         2\n",
      "Style                   1377\n",
      "SKU                     7195\n",
      "Category                   9\n",
      "Size                      11\n",
      "ASIN                    7190\n",
      "Courier Status             4\n",
      "Qty                       10\n",
      "Amount                  1411\n",
      "ship-city               8955\n",
      "ship-state                69\n",
      "ship-postal-code        9459\n",
      "ship-country               1\n",
      "B2B                        2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Explore number of unique values in each column\n",
    "unique_values = df.nunique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], format='%m-%d-%y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                  0\n",
       "Order ID               0\n",
       "Date                   0\n",
       "Status                 0\n",
       "Fulfilment             0\n",
       "Sales Channel          0\n",
       "ship-service-level     0\n",
       "Style                  0\n",
       "SKU                    0\n",
       "Category               0\n",
       "Size                   0\n",
       "ASIN                   0\n",
       "Courier Status         0\n",
       "Qty                    0\n",
       "Amount                 0\n",
       "ship-city             33\n",
       "ship-state            33\n",
       "ship-postal-code      33\n",
       "ship-country          33\n",
       "B2B                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count null value in columns\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns with more than 92 unique values or just one and 'qty' because the weird spread of amount by qty\n",
    "df = df.drop(['ship-country','index', 'Order ID', 'Style', 'SKU', 'ship-city', 'ship-postal-code', 'ASIN', 'Qty'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Status', 'Fulfilment', 'Sales Channel ', 'ship-service-level',\n",
       "       'Category', 'Size', 'Courier Status', 'Amount', 'ship-state', 'B2B'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                    91\n",
      "Status                  13\n",
      "Fulfilment               2\n",
      "Sales Channel            2\n",
      "ship-service-level       2\n",
      "Category                 9\n",
      "Size                    11\n",
      "Courier Status           4\n",
      "Amount                1411\n",
      "ship-state              69\n",
      "B2B                      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_values = df.nunique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct spelling errors in 'ship-state'\n",
    "# Function to correct and standardize state names\n",
    "def correct_state_name(state_name):\n",
    "    corrections = {\n",
    "        'ARUNACHAL PRADESH': 'Arunachal Pradesh',\n",
    "        'Arunachal pradesh': 'Arunachal Pradesh',\n",
    "        'BIHAR': 'Bihar',\n",
    "        'CHANDIGARH': 'Chandigarh',\n",
    "        'DELHI': 'Delhi',\n",
    "        'GOA': 'Goa',\n",
    "        'GUJARAT': 'Gujarat',\n",
    "        'HARYANA': 'Haryana',\n",
    "        'HIMACHAL PRADESH': 'Himachal Pradesh',\n",
    "        'JAMMU & KASHMIR': 'Jammu & Kashmir',\n",
    "        'JHARKHAND': 'Jharkhand',\n",
    "        'KARNATAKA': 'Karnataka',\n",
    "        'KERALA': 'Kerala',\n",
    "        'LADAKH': 'Ladakh',\n",
    "        'LAKSHADWEEP': 'Lakshadweep',\n",
    "        'MADHYA PRADESH': 'Madhya Pradesh',\n",
    "        'MAHARASHTRA': 'Maharashtra',\n",
    "        'MANIPUR': 'Manipur',\n",
    "        'MEGHALAYA': 'Meghalaya',\n",
    "        'MIZORAM': 'Mizoram',\n",
    "        'NAGALAND': 'Nagaland',\n",
    "        'ODISHA': 'Odisha',\n",
    "        'PUDUCHERRY': 'Puducherry',\n",
    "        'PUNJAB': 'Punjab',\n",
    "        'RAJASTHAN': 'Rajasthan',\n",
    "        'SIKKIM': 'Sikkim',\n",
    "        'TAMIL NADU': 'Tamil Nadu',\n",
    "        'TELANGANA': 'Telangana',\n",
    "        'TRIPURA': 'Tripura',\n",
    "        'UTTAR PRADESH': 'Uttar Pradesh',\n",
    "        'UTTARAKHAND': 'Uttarakhand',\n",
    "        'WEST BENGAL': 'West Bengal',\n",
    "        'nan': 'Unknown',\n",
    "        'Rajshthan': 'Rajasthan',\n",
    "        'Rajsthan': 'Rajasthan',\n",
    "        'Orissa': 'Odisha',  # Orissa is the former name of Odisha\n",
    "        'New Delhi': 'Delhi',  # New Delhi is part of Delhi\n",
    "        'Pondicherry': 'Puducherry',  # Pondicherry was renamed to Puducherry\n",
    "        'Punjab/Mohali/Zirakpur': 'Punjab'  # Specific cities in Punjab\n",
    "    }\n",
    "    return corrections.get(state_name, state_name.title())\n",
    "\n",
    "# Apply the corrections to the 'ship-state' column\n",
    "df['ship-state'] = df['ship-state'].apply(correct_state_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode all columns with less than 92 unique values except target column 'Amount'\n",
    "#Make a list of columns except 'Amount'\n",
    "bool_columns_list = [col for col in df if col != 'Amount']\n",
    "#One hot encode list of columns\n",
    "df = pd.get_dummies(df, columns=bool_columns_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the list with all the columns now that they have been one-hot encoded\n",
    "bool_columns_list = [col for col in df if col != 'Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yolo-Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and bool_columns is a list of your boolean column names\n",
    "\n",
    "# Convert boolean columns to float\n",
    "df[bool_columns_list] = df[bool_columns_list].astype(float)\n",
    "\n",
    "# Define your features (X) and target (y) from the DataFrame\n",
    "X = df[bool_columns_list]\n",
    "y = df['Amount']\n",
    "\n",
    "# Splitting the dataset into training and test sets (as you've done)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Further split the training set into a new training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Converting to PyTorch tensors and moving to the specified device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Creating datasets and dataloaders for training, validation, and test sets\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_data = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=750, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=750, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=750, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.6)\n",
    "\n",
    "        self.fc2 = nn.Linear(100, 80)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # New layers added\n",
    "        self.fc3 = nn.Linear(80, 60)  # Size roughly halved from previous layer\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc4 = nn.Linear(60, 40)  # Size roughly halved from previous layer\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc5 = nn.Linear(40, 20)   # Size roughly halved from previous layer\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.dropout5 = nn.Dropout(0.2)\n",
    "\n",
    "        # Final layer\n",
    "        self.fc6 = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # Flow through new layers\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.dropout5(x)\n",
    "\n",
    "        # Final output\n",
    "        x = self.fc6(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = RegressionModel(X_train_tensor.shape[1]).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.005, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "\n",
    "# Define a lambda function for learning rate decay\n",
    "def lr_lambda(epoch):\n",
    "    initial_lr = 0.01\n",
    "    final_lr = 0.001\n",
    "    max_epochs = 20000\n",
    "    decay_rate = (final_lr / initial_lr) ** (1 / max_epochs)\n",
    "    return decay_rate ** epoch\n",
    "scheduler = LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000, Validation R2 Score: 0.3830417378241219\n",
      "Epoch 2/10000, Validation R2 Score: 0.34945896931225273\n",
      "Epoch 3/10000, Validation R2 Score: 0.3554093011205173\n",
      "Epoch 4/10000, Validation R2 Score: 0.35851699176525464\n",
      "Epoch 5/10000, Validation R2 Score: 0.41069079023960486\n",
      "Epoch 6/10000, Validation R2 Score: 0.3937856600871089\n",
      "Epoch 7/10000, Validation R2 Score: 0.3794222254171786\n",
      "Epoch 8/10000, Validation R2 Score: 0.37590793428630065\n",
      "Epoch 9/10000, Validation R2 Score: 0.3664836712949878\n",
      "Epoch 10/10000, Validation R2 Score: 0.39954656990010506\n",
      "Epoch 11/10000, Validation R2 Score: 0.4074567080509085\n",
      "Epoch 12/10000, Validation R2 Score: 0.41613758075389085\n",
      "Epoch 13/10000, Validation R2 Score: 0.42180052616958363\n",
      "Epoch 14/10000, Validation R2 Score: 0.4000541881536296\n",
      "Epoch 15/10000, Validation R2 Score: 0.41512916410922507\n",
      "Epoch 16/10000, Validation R2 Score: 0.38510998694979526\n",
      "Epoch 17/10000, Validation R2 Score: 0.40676407647486645\n",
      "Epoch 18/10000, Validation R2 Score: 0.41561548456968045\n",
      "Epoch 19/10000, Validation R2 Score: 0.4025101993279775\n",
      "Epoch 20/10000, Validation R2 Score: 0.42923012595471643\n",
      "Epoch 21/10000, Validation R2 Score: 0.40854963924270604\n",
      "Epoch 22/10000, Validation R2 Score: 0.4173008483617471\n",
      "Epoch 23/10000, Validation R2 Score: 0.41368972527416614\n",
      "Epoch 24/10000, Validation R2 Score: 0.42203466914534715\n",
      "Epoch 25/10000, Validation R2 Score: 0.39284080564680224\n",
      "Epoch 26/10000, Validation R2 Score: 0.4209572173104942\n",
      "Epoch 27/10000, Validation R2 Score: 0.3959807925861999\n",
      "Epoch 28/10000, Validation R2 Score: 0.4115205893941015\n",
      "Epoch 29/10000, Validation R2 Score: 0.43563942110444875\n",
      "Epoch 30/10000, Validation R2 Score: 0.40788379441620637\n",
      "Epoch 31/10000, Validation R2 Score: 0.4278156726923267\n",
      "Epoch 32/10000, Validation R2 Score: 0.3962486517590448\n",
      "Epoch 33/10000, Validation R2 Score: 0.35156319033873573\n",
      "Epoch 34/10000, Validation R2 Score: 0.4393146906445642\n",
      "Epoch 35/10000, Validation R2 Score: 0.4220297434355498\n",
      "Epoch 36/10000, Validation R2 Score: 0.373768130685569\n",
      "Epoch 37/10000, Validation R2 Score: 0.4311713906764163\n",
      "Epoch 38/10000, Validation R2 Score: 0.40162633307877726\n",
      "Epoch 39/10000, Validation R2 Score: 0.4072560668947711\n",
      "Epoch 40/10000, Validation R2 Score: 0.4365522504526521\n",
      "Epoch 41/10000, Validation R2 Score: 0.41117123637464537\n",
      "Epoch 42/10000, Validation R2 Score: 0.4407222688707402\n",
      "Epoch 43/10000, Validation R2 Score: 0.43252988072931153\n",
      "Epoch 44/10000, Validation R2 Score: 0.42708212370825405\n",
      "Epoch 45/10000, Validation R2 Score: 0.414021429146301\n",
      "Epoch 46/10000, Validation R2 Score: 0.4408292420137383\n",
      "Epoch 47/10000, Validation R2 Score: 0.42446740112336334\n",
      "Epoch 48/10000, Validation R2 Score: 0.43933921903481044\n",
      "Epoch 49/10000, Validation R2 Score: 0.4362640087623071\n",
      "Epoch 50/10000, Validation R2 Score: 0.4399509167597594\n",
      "Epoch 51/10000, Validation R2 Score: 0.4180802408773888\n",
      "Epoch 52/10000, Validation R2 Score: 0.44181437795701306\n",
      "Epoch 53/10000, Validation R2 Score: 0.43559966162649055\n",
      "Epoch 54/10000, Validation R2 Score: 0.44189448252920527\n",
      "Epoch 55/10000, Validation R2 Score: 0.4337041456743542\n",
      "Epoch 56/10000, Validation R2 Score: 0.43025342666520416\n",
      "Epoch 57/10000, Validation R2 Score: 0.42963483742234143\n",
      "Epoch 58/10000, Validation R2 Score: 0.44608921225990994\n",
      "Epoch 59/10000, Validation R2 Score: 0.44234860215617244\n",
      "Epoch 60/10000, Validation R2 Score: 0.4451172098388946\n",
      "Epoch 61/10000, Validation R2 Score: 0.4291419962733678\n",
      "Epoch 62/10000, Validation R2 Score: 0.4438783265561478\n",
      "Epoch 63/10000, Validation R2 Score: 0.43586669404567757\n",
      "Epoch 64/10000, Validation R2 Score: 0.43394789527022326\n",
      "Epoch 65/10000, Validation R2 Score: 0.4339411905145826\n",
      "Epoch 66/10000, Validation R2 Score: 0.433017706887073\n",
      "Epoch 67/10000, Validation R2 Score: 0.4399265862305449\n",
      "Epoch 68/10000, Validation R2 Score: 0.4412820497538551\n",
      "Epoch 69/10000, Validation R2 Score: 0.4328991684964695\n",
      "Epoch 70/10000, Validation R2 Score: 0.4491221802163189\n",
      "Epoch 71/10000, Validation R2 Score: 0.4330971278742798\n",
      "Epoch 72/10000, Validation R2 Score: 0.44085714548021315\n",
      "Epoch 73/10000, Validation R2 Score: 0.4429944854125245\n",
      "Epoch 74/10000, Validation R2 Score: 0.44468765314983827\n",
      "Epoch 75/10000, Validation R2 Score: 0.4313243591337562\n",
      "Epoch 76/10000, Validation R2 Score: 0.4337158651049843\n",
      "Epoch 77/10000, Validation R2 Score: 0.44048086300999834\n",
      "Epoch 78/10000, Validation R2 Score: 0.42913205964934376\n",
      "Epoch 79/10000, Validation R2 Score: 0.43503010992576907\n",
      "Epoch 80/10000, Validation R2 Score: 0.42306897016075007\n",
      "Epoch 81/10000, Validation R2 Score: 0.4368248329586617\n",
      "Epoch 82/10000, Validation R2 Score: 0.44436384597489953\n",
      "Epoch 83/10000, Validation R2 Score: 0.44421114741581813\n",
      "Epoch 84/10000, Validation R2 Score: 0.4302674615921963\n",
      "Epoch 85/10000, Validation R2 Score: 0.4449307142721606\n",
      "Epoch 86/10000, Validation R2 Score: 0.43806286767615776\n",
      "Epoch 87/10000, Validation R2 Score: 0.4437827346383385\n",
      "Epoch 88/10000, Validation R2 Score: 0.44136353108798876\n",
      "Epoch 89/10000, Validation R2 Score: 0.43130565551739175\n",
      "Epoch 90/10000, Validation R2 Score: 0.4465754660437864\n",
      "Epoch 91/10000, Validation R2 Score: 0.43992454149408744\n",
      "Epoch 92/10000, Validation R2 Score: 0.44790158154950843\n",
      "Epoch 93/10000, Validation R2 Score: 0.4349269100092378\n",
      "Epoch 94/10000, Validation R2 Score: 0.4359493616201465\n",
      "Epoch 95/10000, Validation R2 Score: 0.4415352408720701\n",
      "Epoch 96/10000, Validation R2 Score: 0.43989114709623045\n",
      "Epoch 97/10000, Validation R2 Score: 0.4381191386205425\n",
      "Epoch 98/10000, Validation R2 Score: 0.44634169815713576\n",
      "Epoch 99/10000, Validation R2 Score: 0.4393411423802396\n",
      "Epoch 100/10000, Validation R2 Score: 0.4417649935585045\n",
      "Epoch 101/10000, Validation R2 Score: 0.4371471463400086\n",
      "Epoch 102/10000, Validation R2 Score: 0.4467257710636784\n",
      "Epoch 103/10000, Validation R2 Score: 0.4435466680998501\n",
      "Epoch 104/10000, Validation R2 Score: 0.44268110670002503\n",
      "Epoch 105/10000, Validation R2 Score: 0.4439288622049544\n",
      "Epoch 106/10000, Validation R2 Score: 0.436808302243181\n",
      "Epoch 107/10000, Validation R2 Score: 0.44308248669497685\n",
      "Epoch 108/10000, Validation R2 Score: 0.43809802729271163\n",
      "Epoch 109/10000, Validation R2 Score: 0.43220220403045106\n",
      "Epoch 110/10000, Validation R2 Score: 0.4442590602670704\n",
      "Epoch 111/10000, Validation R2 Score: 0.44743754178905126\n",
      "Epoch 112/10000, Validation R2 Score: 0.43752054682718666\n",
      "Epoch 113/10000, Validation R2 Score: 0.44261869220400907\n",
      "Epoch 114/10000, Validation R2 Score: 0.44400546270782515\n",
      "Epoch 115/10000, Validation R2 Score: 0.442315995948663\n",
      "Epoch 116/10000, Validation R2 Score: 0.4361055189575165\n",
      "Epoch 117/10000, Validation R2 Score: 0.4466338125269844\n",
      "Epoch 118/10000, Validation R2 Score: 0.44094592676563127\n",
      "Epoch 119/10000, Validation R2 Score: 0.44170747491961115\n",
      "Epoch 120/10000, Validation R2 Score: 0.44440536480696724\n",
      "Epoch 121/10000, Validation R2 Score: 0.44721234377324215\n",
      "Epoch 122/10000, Validation R2 Score: 0.4393014741170562\n",
      "Epoch 123/10000, Validation R2 Score: 0.43725228762366153\n",
      "Epoch 124/10000, Validation R2 Score: 0.44535234387377864\n",
      "Epoch 125/10000, Validation R2 Score: 0.43976564756776415\n",
      "Epoch 126/10000, Validation R2 Score: 0.4424380223303622\n",
      "Epoch 127/10000, Validation R2 Score: 0.44577026503051154\n",
      "Epoch 128/10000, Validation R2 Score: 0.4376237326492154\n",
      "Epoch 129/10000, Validation R2 Score: 0.4459975531573058\n",
      "Epoch 130/10000, Validation R2 Score: 0.4479386998584496\n",
      "Epoch 131/10000, Validation R2 Score: 0.44737928907965163\n",
      "Epoch 132/10000, Validation R2 Score: 0.4424253830652657\n",
      "Epoch 133/10000, Validation R2 Score: 0.4409835613929529\n",
      "Epoch 134/10000, Validation R2 Score: 0.44284182367487324\n",
      "Epoch 135/10000, Validation R2 Score: 0.4443802194746873\n",
      "Epoch 136/10000, Validation R2 Score: 0.44154396858662504\n",
      "Epoch 137/10000, Validation R2 Score: 0.4451567981494542\n",
      "Epoch 138/10000, Validation R2 Score: 0.4416879558454926\n",
      "Epoch 139/10000, Validation R2 Score: 0.44487883701955944\n",
      "Epoch 140/10000, Validation R2 Score: 0.44682922314806206\n",
      "Epoch 141/10000, Validation R2 Score: 0.44594647895119044\n",
      "Epoch 142/10000, Validation R2 Score: 0.44514708762721367\n",
      "Epoch 143/10000, Validation R2 Score: 0.44452226586416155\n",
      "Epoch 144/10000, Validation R2 Score: 0.4425874149487884\n",
      "Epoch 145/10000, Validation R2 Score: 0.4397571566974807\n",
      "Epoch 146/10000, Validation R2 Score: 0.4468195775368349\n",
      "Epoch 147/10000, Validation R2 Score: 0.4446886399442428\n",
      "Epoch 148/10000, Validation R2 Score: 0.4470299099980578\n",
      "Epoch 149/10000, Validation R2 Score: 0.446801463431413\n",
      "Epoch 150/10000, Validation R2 Score: 0.44339236130275206\n",
      "Epoch 151/10000, Validation R2 Score: 0.44681109969186183\n",
      "Epoch 152/10000, Validation R2 Score: 0.44174942068833256\n",
      "Epoch 153/10000, Validation R2 Score: 0.4471149561535118\n",
      "Epoch 154/10000, Validation R2 Score: 0.44716752800691884\n",
      "Epoch 155/10000, Validation R2 Score: 0.4438443134275647\n",
      "Epoch 156/10000, Validation R2 Score: 0.4417720296166793\n",
      "Epoch 157/10000, Validation R2 Score: 0.4468981175646125\n",
      "Epoch 158/10000, Validation R2 Score: 0.4424413842269279\n",
      "Epoch 159/10000, Validation R2 Score: 0.4466609471947234\n",
      "Epoch 160/10000, Validation R2 Score: 0.4456137866858151\n",
      "Epoch 161/10000, Validation R2 Score: 0.44345523655805197\n",
      "Epoch 162/10000, Validation R2 Score: 0.44712560017237624\n",
      "Epoch 163/10000, Validation R2 Score: 0.44653254978785506\n",
      "Epoch 164/10000, Validation R2 Score: 0.44373504589758683\n",
      "Epoch 165/10000, Validation R2 Score: 0.4426280817279501\n",
      "Epoch 166/10000, Validation R2 Score: 0.44720552659629265\n",
      "Epoch 167/10000, Validation R2 Score: 0.44423619393298874\n",
      "Epoch 168/10000, Validation R2 Score: 0.44551441485967735\n",
      "Epoch 169/10000, Validation R2 Score: 0.4443932900621579\n",
      "Epoch 170/10000, Validation R2 Score: 0.4400097351473574\n",
      "Epoch 171/10000, Validation R2 Score: 0.4439108176754897\n",
      "Epoch 172/10000, Validation R2 Score: 0.445034541726561\n",
      "Epoch 173/10000, Validation R2 Score: 0.4457796583605129\n",
      "Epoch 174/10000, Validation R2 Score: 0.4468801470039224\n",
      "Epoch 175/10000, Validation R2 Score: 0.44454959477782297\n",
      "Epoch 176/10000, Validation R2 Score: 0.4456936785822644\n",
      "Epoch 177/10000, Validation R2 Score: 0.44430107716862677\n",
      "Epoch 178/10000, Validation R2 Score: 0.4453804243758984\n",
      "Epoch 179/10000, Validation R2 Score: 0.4435522361415024\n",
      "Epoch 180/10000, Validation R2 Score: 0.446006317945273\n",
      "Epoch 181/10000, Validation R2 Score: 0.44381624077303594\n",
      "Epoch 182/10000, Validation R2 Score: 0.4454598799130224\n",
      "Epoch 183/10000, Validation R2 Score: 0.4440972438285794\n",
      "Epoch 184/10000, Validation R2 Score: 0.4421878038490846\n",
      "Epoch 185/10000, Validation R2 Score: 0.4423815573710709\n",
      "Epoch 186/10000, Validation R2 Score: 0.4440721662418514\n",
      "Epoch 187/10000, Validation R2 Score: 0.44614985332904933\n",
      "Epoch 188/10000, Validation R2 Score: 0.4440401476843535\n",
      "Epoch 189/10000, Validation R2 Score: 0.44694670036639883\n",
      "Epoch 190/10000, Validation R2 Score: 0.4447626923511451\n",
      "Epoch 191/10000, Validation R2 Score: 0.4451602718729797\n",
      "Epoch 192/10000, Validation R2 Score: 0.43924901130955174\n",
      "Epoch 193/10000, Validation R2 Score: 0.4456084294098581\n",
      "Epoch 194/10000, Validation R2 Score: 0.44422640866387375\n",
      "Epoch 195/10000, Validation R2 Score: 0.4445208584592518\n",
      "Epoch 196/10000, Validation R2 Score: 0.4415646042351329\n",
      "Epoch 197/10000, Validation R2 Score: 0.4451031760427717\n",
      "Epoch 198/10000, Validation R2 Score: 0.4426969683842784\n",
      "Epoch 199/10000, Validation R2 Score: 0.4442145021653956\n",
      "Epoch 200/10000, Validation R2 Score: 0.4465443584045079\n",
      "Epoch 201/10000, Validation R2 Score: 0.44376999091495795\n",
      "Epoch 202/10000, Validation R2 Score: 0.4437759580884846\n",
      "Epoch 203/10000, Validation R2 Score: 0.4434905679526929\n",
      "Epoch 204/10000, Validation R2 Score: 0.4448389141064557\n",
      "Epoch 205/10000, Validation R2 Score: 0.44648029769292197\n",
      "Epoch 206/10000, Validation R2 Score: 0.44641619127691523\n",
      "Epoch 207/10000, Validation R2 Score: 0.44440991393432805\n",
      "Epoch 208/10000, Validation R2 Score: 0.4452099655761189\n",
      "Epoch 209/10000, Validation R2 Score: 0.4462557551268298\n",
      "Epoch 210/10000, Validation R2 Score: 0.44472122516217294\n",
      "Epoch 211/10000, Validation R2 Score: 0.4465241835830075\n",
      "Epoch 212/10000, Validation R2 Score: 0.4471678330787988\n",
      "Epoch 213/10000, Validation R2 Score: 0.4445498086789582\n",
      "Epoch 214/10000, Validation R2 Score: 0.446539443367427\n",
      "Epoch 215/10000, Validation R2 Score: 0.4467636051375481\n",
      "Epoch 216/10000, Validation R2 Score: 0.44506407804831616\n",
      "Epoch 217/10000, Validation R2 Score: 0.44488477995300124\n",
      "Epoch 218/10000, Validation R2 Score: 0.44362944441226293\n",
      "Epoch 219/10000, Validation R2 Score: 0.44288309945030957\n",
      "Epoch 220/10000, Validation R2 Score: 0.4435455569492741\n",
      "Epoch 221/10000, Validation R2 Score: 0.44432357034332004\n",
      "Epoch 222/10000, Validation R2 Score: 0.4456148639135976\n",
      "Epoch 223/10000, Validation R2 Score: 0.445120913375622\n",
      "Epoch 224/10000, Validation R2 Score: 0.4448476113883071\n",
      "Epoch 225/10000, Validation R2 Score: 0.44629936953284965\n",
      "Epoch 226/10000, Validation R2 Score: 0.44608825785104433\n",
      "Epoch 227/10000, Validation R2 Score: 0.44624722254383753\n",
      "Epoch 228/10000, Validation R2 Score: 0.4445148967072651\n",
      "Epoch 229/10000, Validation R2 Score: 0.44254601099423907\n",
      "Epoch 230/10000, Validation R2 Score: 0.443904653134652\n",
      "Epoch 231/10000, Validation R2 Score: 0.44536931001697444\n",
      "Epoch 232/10000, Validation R2 Score: 0.444422375332289\n",
      "Epoch 233/10000, Validation R2 Score: 0.4464788664656534\n",
      "Epoch 234/10000, Validation R2 Score: 0.4456272061869049\n",
      "Epoch 235/10000, Validation R2 Score: 0.44519945172748854\n",
      "Epoch 236/10000, Validation R2 Score: 0.44387898967039285\n",
      "Epoch 237/10000, Validation R2 Score: 0.4463856316996023\n",
      "Epoch 238/10000, Validation R2 Score: 0.44339665913109816\n",
      "Epoch 239/10000, Validation R2 Score: 0.4469608302608036\n",
      "Epoch 240/10000, Validation R2 Score: 0.4446645700619273\n",
      "Epoch 241/10000, Validation R2 Score: 0.4444388352768942\n",
      "Epoch 242/10000, Validation R2 Score: 0.44410914050501904\n",
      "Epoch 243/10000, Validation R2 Score: 0.4447278943734805\n",
      "Epoch 244/10000, Validation R2 Score: 0.4467784484669961\n",
      "Epoch 245/10000, Validation R2 Score: 0.4442164901896388\n",
      "Epoch 246/10000, Validation R2 Score: 0.44503634658958524\n",
      "Epoch 247/10000, Validation R2 Score: 0.4459974229754775\n",
      "Epoch 248/10000, Validation R2 Score: 0.44521248452177475\n",
      "Epoch 249/10000, Validation R2 Score: 0.4447809681075876\n",
      "Epoch 250/10000, Validation R2 Score: 0.4439345559587974\n",
      "Epoch 251/10000, Validation R2 Score: 0.4459260379344473\n",
      "Epoch 252/10000, Validation R2 Score: 0.44564535919225134\n",
      "Epoch 253/10000, Validation R2 Score: 0.44550073840958415\n",
      "Epoch 254/10000, Validation R2 Score: 0.4465302046041044\n",
      "Epoch 255/10000, Validation R2 Score: 0.44563546291847156\n",
      "Epoch 256/10000, Validation R2 Score: 0.4458444033422465\n",
      "Epoch 257/10000, Validation R2 Score: 0.44534268709693947\n",
      "Epoch 258/10000, Validation R2 Score: 0.4426023736583711\n",
      "Epoch 259/10000, Validation R2 Score: 0.44386125427075906\n",
      "Epoch 260/10000, Validation R2 Score: 0.44454820503562975\n",
      "Epoch 261/10000, Validation R2 Score: 0.44615538892445583\n",
      "Epoch 262/10000, Validation R2 Score: 0.44572467799401716\n",
      "Epoch 263/10000, Validation R2 Score: 0.4455666428423113\n",
      "Epoch 264/10000, Validation R2 Score: 0.4425917692040945\n",
      "Epoch 265/10000, Validation R2 Score: 0.44534086385214233\n",
      "Epoch 266/10000, Validation R2 Score: 0.44473454713468463\n",
      "Epoch 267/10000, Validation R2 Score: 0.44460624854070363\n",
      "Epoch 268/10000, Validation R2 Score: 0.44391353400522504\n",
      "Epoch 269/10000, Validation R2 Score: 0.44581356906763214\n",
      "Epoch 270/10000, Validation R2 Score: 0.4441570668205641\n",
      "Epoch 271/10000, Validation R2 Score: 0.4461745880483252\n",
      "Epoch 272/10000, Validation R2 Score: 0.44505773125053305\n",
      "Epoch 273/10000, Validation R2 Score: 0.4447889713545229\n",
      "Epoch 274/10000, Validation R2 Score: 0.44486404869511065\n",
      "Epoch 275/10000, Validation R2 Score: 0.4458190166488164\n",
      "Epoch 276/10000, Validation R2 Score: 0.4444371721004845\n",
      "Epoch 277/10000, Validation R2 Score: 0.44520759013424316\n",
      "Epoch 278/10000, Validation R2 Score: 0.4445339454670063\n",
      "Epoch 279/10000, Validation R2 Score: 0.4446626633162577\n",
      "Epoch 280/10000, Validation R2 Score: 0.4448727958845845\n",
      "Epoch 281/10000, Validation R2 Score: 0.44390097252297467\n",
      "Epoch 282/10000, Validation R2 Score: 0.44505611976411596\n",
      "Epoch 283/10000, Validation R2 Score: 0.4449471368775739\n",
      "Epoch 284/10000, Validation R2 Score: 0.4455085777883714\n",
      "Epoch 285/10000, Validation R2 Score: 0.44544287767349977\n",
      "Epoch 286/10000, Validation R2 Score: 0.44468065497267384\n",
      "Epoch 287/10000, Validation R2 Score: 0.44485211476808295\n",
      "Epoch 288/10000, Validation R2 Score: 0.4463515778331638\n",
      "Epoch 289/10000, Validation R2 Score: 0.4438300501600513\n",
      "Epoch 290/10000, Validation R2 Score: 0.4450457299473931\n",
      "Epoch 291/10000, Validation R2 Score: 0.44669571012730913\n",
      "Epoch 292/10000, Validation R2 Score: 0.44430888019398407\n",
      "Epoch 293/10000, Validation R2 Score: 0.4460561785795375\n",
      "Epoch 294/10000, Validation R2 Score: 0.44495192504462566\n",
      "Epoch 295/10000, Validation R2 Score: 0.4455490834916098\n",
      "Epoch 296/10000, Validation R2 Score: 0.4456821361569234\n",
      "Epoch 297/10000, Validation R2 Score: 0.4457831913381891\n",
      "Epoch 298/10000, Validation R2 Score: 0.44512175278495414\n",
      "Epoch 299/10000, Validation R2 Score: 0.44585830088591993\n",
      "Epoch 300/10000, Validation R2 Score: 0.4464435922121338\n",
      "Epoch 301/10000, Validation R2 Score: 0.44509539517467556\n",
      "Epoch 302/10000, Validation R2 Score: 0.44535100770317493\n",
      "Epoch 303/10000, Validation R2 Score: 0.4435936818135482\n",
      "Epoch 304/10000, Validation R2 Score: 0.44517226520379405\n",
      "Epoch 305/10000, Validation R2 Score: 0.44484199712631023\n",
      "Epoch 306/10000, Validation R2 Score: 0.4453810399901511\n",
      "Epoch 307/10000, Validation R2 Score: 0.44580578268933735\n",
      "Epoch 308/10000, Validation R2 Score: 0.444942972697131\n",
      "Epoch 309/10000, Validation R2 Score: 0.4449910929530273\n",
      "Epoch 310/10000, Validation R2 Score: 0.4447824717696627\n",
      "Epoch 311/10000, Validation R2 Score: 0.44519886892391736\n",
      "Epoch 312/10000, Validation R2 Score: 0.44555639479896425\n",
      "Epoch 313/10000, Validation R2 Score: 0.445652190651023\n",
      "Epoch 314/10000, Validation R2 Score: 0.4453843664377247\n",
      "Epoch 315/10000, Validation R2 Score: 0.44574050539022525\n",
      "Epoch 316/10000, Validation R2 Score: 0.44561052724367445\n",
      "Epoch 317/10000, Validation R2 Score: 0.4460087930653681\n",
      "Epoch 318/10000, Validation R2 Score: 0.44440725235787426\n",
      "Epoch 319/10000, Validation R2 Score: 0.4449732927647877\n",
      "Epoch 320/10000, Validation R2 Score: 0.4459445629306601\n",
      "Epoch 321/10000, Validation R2 Score: 0.4454200325987814\n",
      "Epoch 322/10000, Validation R2 Score: 0.4447072749977313\n",
      "Epoch 323/10000, Validation R2 Score: 0.44522205910277346\n",
      "Epoch 324/10000, Validation R2 Score: 0.4457144485633454\n",
      "Epoch 325/10000, Validation R2 Score: 0.44484490517525554\n",
      "Epoch 326/10000, Validation R2 Score: 0.4458763869820219\n",
      "Epoch 327/10000, Validation R2 Score: 0.44507864168431166\n",
      "Epoch 328/10000, Validation R2 Score: 0.44483381270983424\n",
      "Epoch 329/10000, Validation R2 Score: 0.4449329059404964\n",
      "Epoch 330/10000, Validation R2 Score: 0.4454110849135836\n",
      "Epoch 331/10000, Validation R2 Score: 0.4453057229328373\n",
      "Epoch 332/10000, Validation R2 Score: 0.4451475310297991\n",
      "Epoch 333/10000, Validation R2 Score: 0.4455299016549584\n",
      "Epoch 334/10000, Validation R2 Score: 0.4453369477933866\n",
      "Epoch 335/10000, Validation R2 Score: 0.44526431364567787\n",
      "Epoch 336/10000, Validation R2 Score: 0.4457444584034509\n",
      "Epoch 337/10000, Validation R2 Score: 0.445063429875008\n",
      "Epoch 338/10000, Validation R2 Score: 0.4451318430480309\n",
      "Epoch 339/10000, Validation R2 Score: 0.4450439697529761\n",
      "Epoch 340/10000, Validation R2 Score: 0.4444840467658959\n",
      "Epoch 341/10000, Validation R2 Score: 0.4457322024390318\n",
      "Epoch 342/10000, Validation R2 Score: 0.4452205363909596\n",
      "Epoch 343/10000, Validation R2 Score: 0.4462141007870938\n",
      "Epoch 344/10000, Validation R2 Score: 0.4454524084816587\n",
      "Epoch 345/10000, Validation R2 Score: 0.4460918820453176\n",
      "Epoch 346/10000, Validation R2 Score: 0.4453327220208768\n",
      "Epoch 347/10000, Validation R2 Score: 0.44552837799496237\n",
      "Epoch 348/10000, Validation R2 Score: 0.44533437895694594\n",
      "Epoch 349/10000, Validation R2 Score: 0.44530785920933524\n",
      "Epoch 350/10000, Validation R2 Score: 0.44523323438024354\n",
      "Epoch 351/10000, Validation R2 Score: 0.44548233313518326\n",
      "Epoch 352/10000, Validation R2 Score: 0.4450380187758204\n",
      "Epoch 353/10000, Validation R2 Score: 0.44542393548435644\n",
      "Epoch 354/10000, Validation R2 Score: 0.4451416019750112\n",
      "Epoch 355/10000, Validation R2 Score: 0.4453134047270437\n",
      "Epoch 356/10000, Validation R2 Score: 0.4451016442929656\n",
      "Epoch 357/10000, Validation R2 Score: 0.44494576810442954\n",
      "Epoch 358/10000, Validation R2 Score: 0.44501664578380085\n",
      "Epoch 359/10000, Validation R2 Score: 0.4454612423420051\n",
      "Epoch 360/10000, Validation R2 Score: 0.4453684549578705\n",
      "Epoch 361/10000, Validation R2 Score: 0.44540407185878916\n",
      "Epoch 362/10000, Validation R2 Score: 0.4452451229397355\n",
      "Epoch 363/10000, Validation R2 Score: 0.4453830775276021\n",
      "Epoch 364/10000, Validation R2 Score: 0.44516579755263996\n",
      "Epoch 365/10000, Validation R2 Score: 0.4447053144790184\n",
      "Epoch 366/10000, Validation R2 Score: 0.4447906035983471\n",
      "Epoch 367/10000, Validation R2 Score: 0.4458139007105969\n",
      "Epoch 368/10000, Validation R2 Score: 0.44536352583570893\n",
      "Epoch 369/10000, Validation R2 Score: 0.4452749017894557\n",
      "Epoch 370/10000, Validation R2 Score: 0.4453127676578481\n",
      "Epoch 371/10000, Validation R2 Score: 0.44546875758892246\n",
      "Epoch 372/10000, Validation R2 Score: 0.4456285143615316\n",
      "Epoch 373/10000, Validation R2 Score: 0.44537485571570146\n",
      "Epoch 374/10000, Validation R2 Score: 0.4453287871417907\n",
      "Epoch 375/10000, Validation R2 Score: 0.4452025793096206\n",
      "Epoch 376/10000, Validation R2 Score: 0.44544653231021336\n",
      "Epoch 377/10000, Validation R2 Score: 0.44548946551863433\n",
      "Epoch 378/10000, Validation R2 Score: 0.44519771378228323\n",
      "Epoch 379/10000, Validation R2 Score: 0.44533517277744994\n",
      "Epoch 380/10000, Validation R2 Score: 0.44531038638540266\n",
      "Epoch 381/10000, Validation R2 Score: 0.44516877477948547\n",
      "Epoch 382/10000, Validation R2 Score: 0.44539811583968614\n",
      "Epoch 383/10000, Validation R2 Score: 0.4453151686631299\n",
      "Epoch 384/10000, Validation R2 Score: 0.44571651059418993\n",
      "Epoch 385/10000, Validation R2 Score: 0.4453276028126094\n",
      "Epoch 386/10000, Validation R2 Score: 0.4453038910274606\n",
      "Epoch 387/10000, Validation R2 Score: 0.4449378462767327\n",
      "Epoch 388/10000, Validation R2 Score: 0.445402554487523\n",
      "Epoch 389/10000, Validation R2 Score: 0.4450968033307652\n",
      "Epoch 390/10000, Validation R2 Score: 0.44533259143878745\n",
      "Epoch 391/10000, Validation R2 Score: 0.4450832189783014\n",
      "Epoch 392/10000, Validation R2 Score: 0.4456630790647492\n",
      "Epoch 393/10000, Validation R2 Score: 0.44522843088843755\n",
      "Epoch 394/10000, Validation R2 Score: 0.44541171949226877\n",
      "Epoch 395/10000, Validation R2 Score: 0.4454901015518915\n",
      "Epoch 396/10000, Validation R2 Score: 0.44547934561223734\n",
      "Epoch 397/10000, Validation R2 Score: 0.4455827849646288\n",
      "Epoch 398/10000, Validation R2 Score: 0.445455825755678\n",
      "Epoch 399/10000, Validation R2 Score: 0.44477286278354433\n",
      "Epoch 400/10000, Validation R2 Score: 0.445293114933349\n",
      "Epoch 401/10000, Validation R2 Score: 0.4455158587213499\n",
      "Epoch 402/10000, Validation R2 Score: 0.4453319908425032\n",
      "Epoch 403/10000, Validation R2 Score: 0.44530726965730016\n",
      "Epoch 404/10000, Validation R2 Score: 0.4455115185839509\n",
      "Epoch 405/10000, Validation R2 Score: 0.44546894466189657\n",
      "Epoch 406/10000, Validation R2 Score: 0.4454499921047105\n",
      "Epoch 407/10000, Validation R2 Score: 0.44533838196183195\n",
      "Epoch 408/10000, Validation R2 Score: 0.4455780738170314\n",
      "Epoch 409/10000, Validation R2 Score: 0.4454901030407813\n",
      "Epoch 410/10000, Validation R2 Score: 0.445429938584616\n",
      "Epoch 411/10000, Validation R2 Score: 0.44536262341903865\n",
      "Epoch 412/10000, Validation R2 Score: 0.44539161879863287\n",
      "Epoch 413/10000, Validation R2 Score: 0.44538938070527134\n",
      "Epoch 414/10000, Validation R2 Score: 0.44531605188804657\n",
      "Epoch 415/10000, Validation R2 Score: 0.44524331970883635\n",
      "Epoch 416/10000, Validation R2 Score: 0.44516640286919373\n",
      "Epoch 417/10000, Validation R2 Score: 0.445473602117332\n",
      "Epoch 418/10000, Validation R2 Score: 0.44558940518177714\n",
      "Epoch 419/10000, Validation R2 Score: 0.44530963226500897\n",
      "Epoch 420/10000, Validation R2 Score: 0.44499147071226297\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     34\u001b[0m val_targets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m     36\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     37\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(X)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_comp_pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_comp_pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_comp_pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_comp_pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_comp_pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_comp_pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_comp_pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\MLBIA_comp_pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "# Optimizer: Adam with specified parameters and a learning rate of 0.001\n",
    "\n",
    "n_epochs = 10000\n",
    "early_stop_threshold = 0.99\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)  # Move data to the device\n",
    "        \n",
    "        # Clear the gradients of all optimized tensors\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(output.view(-1), target)\n",
    "        \n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # Update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            val_predictions.extend(outputs.view(-1).cpu().numpy())\n",
    "            val_targets.extend(y.cpu().numpy())\n",
    "        \n",
    "        val_r2_score = r2_score(val_targets, val_predictions)\n",
    "        print(f'Epoch {epoch+1}/{n_epochs}, Validation R2 Score: {val_r2_score}')\n",
    "\n",
    "        if val_r2_score >= early_stop_threshold:\n",
    "            print(f\"Early stopping at epoch {epoch+1} with R2 Score: {val_r2_score}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model in detail\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor).view(-1)\n",
    "    \n",
    "    # Convert tensors to numpy arrays for compatibility with sklearn metrics\n",
    "    y_test_np = y_test_tensor.cpu().numpy()\n",
    "    predictions_np = predictions.cpu().numpy()\n",
    "\n",
    "    # Calculating MAE\n",
    "    mae = mean_absolute_error(y_test_np, predictions_np)\n",
    "    print(f'MAE: {mae}')\n",
    "\n",
    "    # RMSE (already calculated)\n",
    "    mse = criterion(predictions, y_test_tensor)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    print(f'RMSE: {rmse.item()}')\n",
    "\n",
    "    # R2 Score (already calculated)\n",
    "    r2 = r2_score(y_test_np, predictions_np)\n",
    "    print(f'R2 Score: {r2}')\n",
    "\n",
    "    # Calculating MAPE\n",
    "    mape = np.mean(np.abs((y_test_np - predictions_np) / y_test_np)) * 100\n",
    "    print(f'MAPE: {mape}')\n",
    "\n",
    "    # Adjusted R2 (for multiple regression models)\n",
    "    n = len(y_test_np) # Number of samples\n",
    "    p = X_test_tensor.shape[1] # Number of independent variables\n",
    "    adjusted_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "    print(f'Adjusted R2 Score: {adjusted_r2}')\n",
    "\n",
    "    print(\"---------First 10 Predictions---------\")\n",
    "    for actual, predicted in zip(y_test_np[:10], predictions_np[:10]):\n",
    "        absolute_error = np.abs(actual - predicted)\n",
    "        relative_error = (absolute_error / actual) * 100 if actual != 0 else float('inf')\n",
    "        print(f\"Actual/Predicted: {actual}/{predicted}\")\n",
    "        print(f\"Abs Error: {absolute_error}\")\n",
    "        print(f\"Rel Error: {relative_error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "#torch.save(model, 'Amazon.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLBIA_comp_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
