{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yolo-Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('onetoohot.csv', low_memory=False)\n",
    "bool_columns_list = [col for col in df if col != 'Amount']\n",
    "# Define your features (X) and target (y) from the DataFrame\n",
    "X = df[bool_columns_list]\n",
    "y = df['Amount']\n",
    "\n",
    "# Splitting the dataset into training and test sets (as you've done)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Further split the training set into a new training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Converting to PyTorch tensors and moving to the specified device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Creating datasets and dataloaders for training, validation, and test sets\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_data = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=750, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=750, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=750, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.dropout1 = nn.Dropout(0.2)  # First dropout layer\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.dropout2 = nn.Dropout(0.2)  # Second dropout layer\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.dropout3 = nn.Dropout(0.2)  # Third dropout layer\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.dropout4 = nn.Dropout(0.2)  # Fourth dropout layer\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.dropout5 = nn.Dropout(0.2)  # Fifth dropout layer\n",
    "        self.fc6 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.relu(self.fc5(x))\n",
    "        x = self.dropout5(x)\n",
    "        x = self.fc6(x)  # Apply the last linear layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = RegressionModel(X_train_tensor.shape[1]).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.005, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "\n",
    "# Define a lambda function for learning rate decay\n",
    "def lr_lambda(epoch):\n",
    "    initial_lr = 0.05\n",
    "    final_lr = 0.001\n",
    "    max_epochs = 20000\n",
    "    decay_rate = (final_lr / initial_lr) ** (1 / max_epochs)\n",
    "    return decay_rate ** epoch\n",
    "scheduler = LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000, Validation R2 Score: 0.3838223477529259\n",
      "Epoch 2/20000, Validation R2 Score: 0.4215249346062333\n",
      "Epoch 3/20000, Validation R2 Score: 0.42283694029547714\n",
      "Epoch 4/20000, Validation R2 Score: 0.38752958167632845\n",
      "Epoch 5/20000, Validation R2 Score: 0.4340490285160814\n",
      "Epoch 6/20000, Validation R2 Score: 0.4160547053843662\n",
      "Epoch 7/20000, Validation R2 Score: 0.422520580843072\n",
      "Epoch 8/20000, Validation R2 Score: 0.42575521687866336\n",
      "Epoch 9/20000, Validation R2 Score: 0.44379267772977626\n",
      "Epoch 10/20000, Validation R2 Score: 0.4341952369553411\n",
      "Epoch 11/20000, Validation R2 Score: 0.4122952387350848\n",
      "Epoch 12/20000, Validation R2 Score: 0.4435105913285926\n",
      "Epoch 13/20000, Validation R2 Score: 0.43761709830430684\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "# Optimizer: Adam with specified parameters and a learning rate of 0.001\n",
    "\n",
    "n_epochs = 20000\n",
    "early_stop_threshold = 0.85\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)  # Move data to the device\n",
    "        \n",
    "        # Clear the gradients of all optimized tensors\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(output.view(-1), target)\n",
    "        \n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # Update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            val_predictions.extend(outputs.view(-1).cpu().numpy())\n",
    "            val_targets.extend(y.cpu().numpy())\n",
    "        \n",
    "        val_r2_score = r2_score(val_targets, val_predictions)\n",
    "        print(f'Epoch {epoch+1}/{n_epochs}, Validation R2 Score: {val_r2_score}')\n",
    "\n",
    "        if val_r2_score >= early_stop_threshold:\n",
    "            print(f\"Early stopping at epoch {epoch+1} with R2 Score: {val_r2_score}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model in detail\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor).view(-1)\n",
    "    \n",
    "    # Convert tensors to numpy arrays for compatibility with sklearn metrics\n",
    "    y_test_np = y_test_tensor.cpu().numpy()\n",
    "    predictions_np = predictions.cpu().numpy()\n",
    "\n",
    "    # Calculating MAE\n",
    "    mae = mean_absolute_error(y_test_np, predictions_np)\n",
    "    print(f'MAE: {mae}')\n",
    "\n",
    "    # RMSE (already calculated)\n",
    "    mse = criterion(predictions, y_test_tensor)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    print(f'RMSE: {rmse.item()}')\n",
    "\n",
    "    # R2 Score (already calculated)\n",
    "    r2 = r2_score(y_test_np, predictions_np)\n",
    "    print(f'R2 Score: {r2}')\n",
    "\n",
    "    # Calculating MAPE\n",
    "    mape = np.mean(np.abs((y_test_np - predictions_np) / y_test_np)) * 100\n",
    "    print(f'MAPE: {mape}')\n",
    "\n",
    "    # Adjusted R2 (for multiple regression models)\n",
    "    n = len(y_test_np) # Number of samples\n",
    "    p = X_test_tensor.shape[1] # Number of independent variables\n",
    "    adjusted_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "    print(f'Adjusted R2 Score: {adjusted_r2}')\n",
    "\n",
    "    print(\"---------First 10 Predictions---------\")\n",
    "    for actual, predicted in zip(y_test_np[:10], predictions_np[:10]):\n",
    "        absolute_error = np.abs(actual - predicted)\n",
    "        relative_error = (absolute_error / actual) * 100 if actual != 0 else float('inf')\n",
    "        print(f\"Actual/Predicted: {actual}/{predicted}\")\n",
    "        print(f\"Abs Error: {absolute_error}\")\n",
    "        print(f\"Rel Error: {relative_error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "#torch.save(model, 'Amazon.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLBIA_comp_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
