{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the column names based on the inferred structure\n",
    "columns = ['geonameid', 'name', 'asciiname', 'alternatenames', 'latitude', 'longitude', 'feature class', 'feature code', 'country code', 'cc2', 'admin1 code', 'admin2 code', 'admin3 code', 'admin4 code', 'population', 'elevation', 'dem', 'timezone', 'modification date']\n",
    "\n",
    "# Read the file (replace 'path_to_file' with the actual file path)\n",
    "df = pd.read_csv('IN.txt', delimiter='\\t', names=columns, low_memory=False, encoding='utf-8')\n",
    "\n",
    "\n",
    "# Filter for cities/towns (feature class 'P')\n",
    "cities_df = df[df['feature class'] == 'P']\n",
    "\n",
    "# Extract relevant columns (you can adjust these as needed)\n",
    "extracted_cities = cities_df[['name', 'latitude', 'longitude', 'population']]\n",
    "\n",
    "\n",
    "# Assuming 'extracted_cities' is a DataFrame created from slicing another DataFrame\n",
    "extracted_cities.loc[:, 'name'] = extracted_cities['name'].str.lower()\n",
    "\n",
    "\n",
    "# Save as csv\n",
    "extracted_cities.to_csv('IndianCities.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indian-city    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check for null values in extraced_cities\n",
    "# Check for null values in extracted_cities\n",
    "null_values = extracted_cities.isnull().sum()\n",
    "print(null_values)\n",
    "#drop null value\n",
    "# Drop null values in extracted_cities\n",
    "extracted_cities.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'latitude', 'longitude', 'population'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_cities.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename and keep only 'name'\n",
    "extracted_cities = extracted_cities[['name']]\n",
    "extracted_cities = extracted_cities.rename(columns={'name': 'indian-city'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['indian-city'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_cities.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import unicodedata\n",
    "\n",
    "# Function to normalize unicode characters\n",
    "def normalize_string(input_str):\n",
    "    if isinstance(input_str, str):\n",
    "        normalized_str = unicodedata.normalize('NFKD', input_str).encode('ascii', 'ignore').decode('ascii')\n",
    "        return normalized_str\n",
    "    else:\n",
    "        return input_str\n",
    "\n",
    "# Assuming 'extracted_cities' DataFrame has a column 'indian-city'\n",
    "# Normalize the 'indian-city' column\n",
    "extracted_cities['indian-city'] = extracted_cities['indian-city'].apply(normalize_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all values in 'indian-city' are strings\n",
    "extracted_cities['indian-city'] = extracted_cities['indian-city'].astype(str)\n",
    "\n",
    "# Step 4: Split and save the dataset\n",
    "for letter in set(extracted_cities['indian-city'].str[0].str.lower()):\n",
    "    subset_df = extracted_cities[extracted_cities['indian-city'].str.startswith(letter, na=False)]\n",
    "    subset_df.to_csv(f'indian_city_{letter}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLBIA_CPU_tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
