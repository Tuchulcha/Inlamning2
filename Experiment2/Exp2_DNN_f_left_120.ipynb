{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from joblib import dump\n",
    "import geohash2 as geohash\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from csv file\n",
    "df = pd.read_csv('onetoothotfeaturesleft120.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yolo-Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the list with all the columns now that they have been one-hot encoded\n",
    "bool_columns_list = [col for col in df if col != 'Amount']\n",
    "# Convert boolean columns to float\n",
    "df[bool_columns_list] = df[bool_columns_list].astype(float)\n",
    "\n",
    "# Define your features (X) and target (y) from the DataFrame\n",
    "X = df[bool_columns_list]\n",
    "y = df['Amount']\n",
    "\n",
    "# Splitting the dataset into training and test sets (as you've done)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Further split the training set into a new training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Converting to PyTorch tensors and moving to the specified device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Creating datasets and dataloaders for training, validation, and test sets\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_data = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=750, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=750, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=750, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)  # Dynamically set input size\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with the correct input size\n",
    "input_size = X_train_tensor.shape[1]\n",
    "model = RegressionModel(input_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.005, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "# Define a lambda function for learning rate decay\n",
    "def lr_lambda(epoch):\n",
    "    initial_lr = 0.01\n",
    "    final_lr = 0.001\n",
    "    max_epochs = 200\n",
    "    decay_rate = (final_lr / initial_lr) ** (1 / max_epochs)\n",
    "    return decay_rate ** epoch\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Validation R2 Score: 0.2899299700609046\n",
      "Epoch 2/200, Validation R2 Score: 0.3247988982024922\n",
      "Epoch 3/200, Validation R2 Score: 0.32889772821533125\n",
      "Epoch 4/200, Validation R2 Score: 0.32836116611429456\n",
      "Epoch 5/200, Validation R2 Score: 0.3286887542606901\n",
      "Epoch 6/200, Validation R2 Score: 0.328716484477929\n",
      "Epoch 7/200, Validation R2 Score: 0.32872019641909145\n",
      "Epoch 8/200, Validation R2 Score: 0.3287174675728115\n",
      "Epoch 9/200, Validation R2 Score: 0.32871705938212337\n",
      "Epoch 10/200, Validation R2 Score: 0.3287170437031499\n",
      "Epoch 11/200, Validation R2 Score: 0.3287170433529111\n",
      "Epoch 12/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 13/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 14/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 15/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 16/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 17/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 18/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 19/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 20/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 21/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 22/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 23/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 24/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 25/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 26/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 27/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 28/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 29/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 30/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 31/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 32/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 33/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 34/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 35/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 36/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 37/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 38/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 39/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 40/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 41/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 42/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 43/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 44/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 45/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 46/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 47/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 48/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 49/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 50/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 51/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 52/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 53/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 54/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 55/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 56/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 57/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 58/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 59/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 60/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 61/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 62/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 63/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 64/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 65/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 66/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 67/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 68/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 69/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 70/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 71/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 72/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 73/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 74/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 75/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 76/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 77/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 78/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 79/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 80/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 81/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 82/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 83/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 84/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 85/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 86/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 87/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 88/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 89/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 90/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 91/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 92/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 93/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 94/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 95/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 96/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 97/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 98/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 99/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 100/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 101/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 102/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 103/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 104/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 105/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 106/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 107/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 108/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 109/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 110/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 111/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 112/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 113/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 114/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 115/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 116/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 117/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 118/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 119/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 120/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 121/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 122/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 123/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 124/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 125/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 126/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 127/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 128/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 129/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 130/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 131/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 132/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 133/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 134/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 135/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 136/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 137/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 138/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 139/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 140/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 141/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 142/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 143/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 144/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 145/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 146/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 147/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 148/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 149/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 150/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 151/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 152/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 153/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 154/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 155/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 156/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 157/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 158/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 159/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 160/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 161/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 162/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 163/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 164/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 165/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 166/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 167/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 168/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 169/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 170/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 171/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 172/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 173/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 174/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 175/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 176/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 177/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 178/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 179/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 180/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 181/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 182/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 183/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 184/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 185/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 186/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 187/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 188/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 189/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 190/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 191/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 192/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 193/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 194/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 195/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 196/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 197/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 198/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 199/200, Validation R2 Score: 0.3287170432444626\n",
      "Epoch 200/200, Validation R2 Score: 0.3287170432444626\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "# Optimizer: Adam with specified parameters and a learning rate of 0.001\n",
    "\n",
    "n_epochs = 200\n",
    "early_stop_threshold = 0.99\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)  # Move data to the device\n",
    "        \n",
    "        # Clear the gradients of all optimized tensors\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = criterion(output.view(-1), target)\n",
    "        \n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # Update running training loss\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            val_predictions.extend(outputs.view(-1).cpu().numpy())\n",
    "            val_targets.extend(y.cpu().numpy())\n",
    "        \n",
    "        val_r2_score = r2_score(val_targets, val_predictions)\n",
    "        print(f'Epoch {epoch+1}/{n_epochs}, Validation R2 Score: {val_r2_score}')\n",
    "\n",
    "        if val_r2_score >= early_stop_threshold:\n",
    "            print(f\"Early stopping at epoch {epoch+1} with R2 Score: {val_r2_score}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 155.7783966064453\n",
      "RMSE: 220.49118041992188\n",
      "R2 Score: 0.3440856990659066\n",
      "MAPE: inf\n",
      "Adjusted R2 Score: 0.34002504971562264\n",
      "---------First 10 Predictions---------\n",
      "Actual/Predicted: 599.0/765.8854370117188\n",
      "Abs Error: 166.88543701171875\n",
      "Rel Error: 27.86%\n",
      "Actual/Predicted: 435.0/469.7935791015625\n",
      "Abs Error: 34.7935791015625\n",
      "Rel Error: 8.00%\n",
      "Actual/Predicted: 1523.0/821.1394653320312\n",
      "Abs Error: 701.8605346679688\n",
      "Rel Error: 46.08%\n",
      "Actual/Predicted: 648.5614624023438/497.5504150390625\n",
      "Abs Error: 151.01104736328125\n",
      "Rel Error: 23.28%\n",
      "Actual/Predicted: 845.0/843.7976684570312\n",
      "Abs Error: 1.20233154296875\n",
      "Rel Error: 0.14%\n",
      "Actual/Predicted: 376.0/433.5589599609375\n",
      "Abs Error: 57.5589599609375\n",
      "Rel Error: 15.31%\n",
      "Actual/Predicted: 416.0/360.300048828125\n",
      "Abs Error: 55.699951171875\n",
      "Rel Error: 13.39%\n",
      "Actual/Predicted: 899.0/667.7276000976562\n",
      "Abs Error: 231.27239990234375\n",
      "Rel Error: 25.73%\n",
      "Actual/Predicted: 648.5614624023438/679.5083618164062\n",
      "Abs Error: 30.9468994140625\n",
      "Rel Error: 4.77%\n",
      "Actual/Predicted: 951.4299926757812/700.4938354492188\n",
      "Abs Error: 250.9361572265625\n",
      "Rel Error: 26.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tono\\AppData\\Local\\Temp\\ipykernel_7152\\3384580297.py:26: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y_test_np - predictions_np) / y_test_np)) * 100\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model in detail\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor).view(-1)\n",
    "    \n",
    "    # Convert tensors to numpy arrays for compatibility with sklearn metrics\n",
    "    y_test_np = y_test_tensor.cpu().numpy()\n",
    "    predictions_np = predictions.cpu().numpy()\n",
    "\n",
    "    # Calculating MAE\n",
    "    mae = mean_absolute_error(y_test_np, predictions_np)\n",
    "    print(f'MAE: {mae}')\n",
    "\n",
    "    # RMSE (already calculated)\n",
    "    mse = criterion(predictions, y_test_tensor)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    print(f'RMSE: {rmse.item()}')\n",
    "\n",
    "    # R2 Score (already calculated)\n",
    "    r2 = r2_score(y_test_np, predictions_np)\n",
    "    print(f'R2 Score: {r2}')\n",
    "\n",
    "    # Calculating MAPE\n",
    "    mape = np.mean(np.abs((y_test_np - predictions_np) / y_test_np)) * 100\n",
    "    print(f'MAPE: {mape}')\n",
    "\n",
    "    # Adjusted R2 (for multiple regression models)\n",
    "    n = len(y_test_np) # Number of samples\n",
    "    p = X_test_tensor.shape[1] # Number of independent variables\n",
    "    adjusted_r2 = 1 - (1-r2)*(n-1)/(n-p-1)\n",
    "    print(f'Adjusted R2 Score: {adjusted_r2}')\n",
    "\n",
    "    print(\"---------First 10 Predictions---------\")\n",
    "    for actual, predicted in zip(y_test_np[:10], predictions_np[:10]):\n",
    "        absolute_error = np.abs(actual - predicted)\n",
    "        relative_error = (absolute_error / actual) * 100 if actual != 0 else float('inf')\n",
    "        print(f\"Actual/Predicted: {actual}/{predicted}\")\n",
    "        print(f\"Abs Error: {absolute_error}\")\n",
    "        print(f\"Rel Error: {relative_error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "#torch.save(model, 'Amazon.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLBIA_comp_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
