{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/300, Loss: 0.6998688257657565\n",
      "Epoch 2/300, Loss: 0.679802289375892\n",
      "Epoch 3/300, Loss: 0.6598549347657424\n",
      "Epoch 4/300, Loss: 0.6377635873281039\n",
      "Epoch 5/300, Loss: 0.6254522296098562\n",
      "Epoch 6/300, Loss: 0.6050324898499709\n",
      "Epoch 7/300, Loss: 0.5860171959950373\n",
      "Epoch 8/300, Loss: 0.5648997013385479\n",
      "Epoch 9/300, Loss: 0.5477574834456811\n",
      "Epoch 10/300, Loss: 0.5317598741788131\n",
      "Epoch 11/300, Loss: 0.5241143336662879\n",
      "Epoch 12/300, Loss: 0.5016779670348535\n",
      "Epoch 13/300, Loss: 0.48570096492767334\n",
      "Epoch 14/300, Loss: 0.47090478585316586\n",
      "Epoch 15/300, Loss: 0.462982890697626\n",
      "Epoch 16/300, Loss: 0.4424450695514679\n",
      "Epoch 17/300, Loss: 0.43076157799133885\n",
      "Epoch 18/300, Loss: 0.41286881611897397\n",
      "Epoch 19/300, Loss: 0.4031100915028499\n",
      "Epoch 20/300, Loss: 0.3972616264453301\n",
      "Epoch 21/300, Loss: 0.3799059666120089\n",
      "Epoch 22/300, Loss: 0.37135080190805286\n",
      "Epoch 23/300, Loss: 0.3582452741953043\n",
      "Epoch 24/300, Loss: 0.3436262641961758\n",
      "Epoch 25/300, Loss: 0.33545022973647487\n",
      "Epoch 26/300, Loss: 0.32487281927695644\n",
      "Epoch 27/300, Loss: 0.31592326439343965\n",
      "Epoch 28/300, Loss: 0.3042092415002676\n",
      "Epoch 29/300, Loss: 0.29986318143514484\n",
      "Epoch 30/300, Loss: 0.29118247674061704\n",
      "Epoch 31/300, Loss: 0.27956195634145004\n",
      "Epoch 32/300, Loss: 0.2747161617645851\n",
      "Epoch 33/300, Loss: 0.26463119914898503\n",
      "Epoch 34/300, Loss: 0.25733715754288894\n",
      "Epoch 35/300, Loss: 0.24953428827799284\n",
      "Epoch 36/300, Loss: 0.24338988501292008\n",
      "Epoch 37/300, Loss: 0.23514763323160318\n",
      "Epoch 38/300, Loss: 0.22700694088752454\n",
      "Epoch 39/300, Loss: 0.22087266353460458\n",
      "Epoch 40/300, Loss: 0.21270233965837038\n",
      "Epoch 41/300, Loss: 0.20902868188344514\n",
      "Epoch 42/300, Loss: 0.20066595650636232\n",
      "Epoch 43/300, Loss: 0.19829334433262163\n",
      "Epoch 44/300, Loss: 0.19128844715081728\n",
      "Epoch 45/300, Loss: 0.18553007336763236\n",
      "Epoch 46/300, Loss: 0.182187842635008\n",
      "Epoch 47/300, Loss: 0.177947631249061\n",
      "Epoch 48/300, Loss: 0.1694351635300196\n",
      "Epoch 49/300, Loss: 0.16718394939716047\n",
      "Epoch 50/300, Loss: 0.16532905170550713\n",
      "Epoch 51/300, Loss: 0.16147268620821145\n",
      "Epoch 52/300, Loss: 0.1552686095237732\n",
      "Epoch 53/300, Loss: 0.15067802312282416\n",
      "Epoch 54/300, Loss: 0.1486432495025488\n",
      "Epoch 55/300, Loss: 0.14583747203533465\n",
      "Epoch 56/300, Loss: 0.14204922318458557\n",
      "Epoch 57/300, Loss: 0.13698226729264626\n",
      "Epoch 58/300, Loss: 0.13609145524410102\n",
      "Epoch 59/300, Loss: 0.13204836272276366\n",
      "Epoch 60/300, Loss: 0.12985830352856562\n",
      "Epoch 61/300, Loss: 0.12911986502317283\n",
      "Epoch 62/300, Loss: 0.12486702031814136\n",
      "Epoch 63/300, Loss: 0.1233565669793349\n",
      "Epoch 64/300, Loss: 0.12194505161963977\n",
      "Epoch 65/300, Loss: 0.11710044283133286\n",
      "Epoch 66/300, Loss: 0.1174813061952591\n",
      "Epoch 67/300, Loss: 0.11350431465185605\n",
      "Epoch 68/300, Loss: 0.11316772836905259\n",
      "Epoch 69/300, Loss: 0.11124151371992551\n",
      "Epoch 70/300, Loss: 0.10894863479412518\n",
      "Epoch 71/300, Loss: 0.10795974616820996\n",
      "Epoch 72/300, Loss: 0.10600219323084904\n",
      "Epoch 73/300, Loss: 0.10605975469717613\n",
      "Epoch 74/300, Loss: 0.1041759026165192\n",
      "Epoch 75/300, Loss: 0.1026383311702655\n",
      "Epoch 76/300, Loss: 0.10174954739900735\n",
      "Epoch 77/300, Loss: 0.10114076275091904\n",
      "Epoch 78/300, Loss: 0.09902456402778625\n",
      "Epoch 79/300, Loss: 0.09993075006283246\n",
      "Epoch 80/300, Loss: 0.09731927284827599\n",
      "Epoch 81/300, Loss: 0.09596403401631576\n",
      "Epoch 82/300, Loss: 0.09611897629040939\n",
      "Epoch 83/300, Loss: 0.0950917498423503\n",
      "Epoch 84/300, Loss: 0.09394870755764154\n",
      "Epoch 85/300, Loss: 0.09339697716327813\n",
      "Epoch 86/300, Loss: 0.09238084119099838\n",
      "Epoch 87/300, Loss: 0.09223853567471871\n",
      "Epoch 88/300, Loss: 0.09139389430101101\n",
      "Epoch 89/300, Loss: 0.09051082340570596\n",
      "Epoch 90/300, Loss: 0.09045518304292972\n",
      "Epoch 91/300, Loss: 0.09076901009449592\n",
      "Epoch 92/300, Loss: 0.08957369167071122\n",
      "Epoch 93/300, Loss: 0.08909632724065047\n",
      "Epoch 94/300, Loss: 0.0892450545842831\n",
      "Epoch 95/300, Loss: 0.08874880579801706\n",
      "Epoch 96/300, Loss: 0.08826161634463531\n",
      "Epoch 97/300, Loss: 0.08835977545151344\n",
      "Epoch 98/300, Loss: 0.08711146391355075\n",
      "Epoch 99/300, Loss: 0.08826493357236569\n",
      "Epoch 100/300, Loss: 0.08750163076015618\n",
      "Epoch 101/300, Loss: 0.08701629707446465\n",
      "Epoch 102/300, Loss: 0.08667998245129219\n",
      "Epoch 103/300, Loss: 0.08682709129957053\n",
      "Epoch 104/300, Loss: 0.0867058875469061\n",
      "Epoch 105/300, Loss: 0.0862246912259322\n",
      "Epoch 106/300, Loss: 0.08624421575894722\n",
      "Epoch 107/300, Loss: 0.08588873824247947\n",
      "Epoch 108/300, Loss: 0.08532510353968693\n",
      "Epoch 109/300, Loss: 0.08468448399351193\n",
      "Epoch 110/300, Loss: 0.08533898339821742\n",
      "Epoch 111/300, Loss: 0.08544804614323837\n",
      "Epoch 112/300, Loss: 0.0850611483821502\n",
      "Epoch 113/300, Loss: 0.08513096318795131\n",
      "Epoch 114/300, Loss: 0.08584174800377625\n",
      "Epoch 115/300, Loss: 0.08552266771976764\n",
      "Epoch 116/300, Loss: 0.08518275733177479\n",
      "Epoch 117/300, Loss: 0.08508471112984878\n",
      "Epoch 118/300, Loss: 0.08441408551656283\n",
      "Epoch 119/300, Loss: 0.0853826621404061\n",
      "Epoch 120/300, Loss: 0.08511794874301323\n",
      "Epoch 121/300, Loss: 0.08506686297746804\n",
      "Epoch 122/300, Loss: 0.08570687300883807\n",
      "Epoch 123/300, Loss: 0.08499766485049175\n",
      "Epoch 124/300, Loss: 0.08422438284525505\n",
      "Epoch 125/300, Loss: 0.08429168164730072\n",
      "Epoch 126/300, Loss: 0.08539511951116416\n",
      "Epoch 127/300, Loss: 0.08478627927028216\n",
      "Epoch 128/300, Loss: 0.0852835000707553\n",
      "Epoch 129/300, Loss: 0.08501641223063836\n",
      "Epoch 130/300, Loss: 0.0835554081086929\n",
      "Epoch 131/300, Loss: 0.08561681726804146\n",
      "Epoch 132/300, Loss: 0.08547529406272449\n",
      "Epoch 133/300, Loss: 0.08517896957122363\n",
      "Epoch 134/300, Loss: 0.08481000650387543\n",
      "Epoch 135/300, Loss: 0.08504851506306575\n",
      "Epoch 136/300, Loss: 0.08464158784884673\n",
      "Epoch 137/300, Loss: 0.08476130778972919\n",
      "Epoch 138/300, Loss: 0.0845220060302661\n",
      "Epoch 139/300, Loss: 0.08531838483535327\n",
      "Epoch 140/300, Loss: 0.08491044491529465\n",
      "Epoch 141/300, Loss: 0.08414856516397916\n",
      "Epoch 142/300, Loss: 0.08547724267611137\n",
      "Epoch 143/300, Loss: 0.08464888425973746\n",
      "Epoch 144/300, Loss: 0.08529188770514268\n",
      "Epoch 145/300, Loss: 0.0847602068231656\n",
      "Epoch 146/300, Loss: 0.08450376700896484\n",
      "Epoch 147/300, Loss: 0.08388493152765128\n",
      "Epoch 148/300, Loss: 0.08534174813674046\n",
      "Epoch 149/300, Loss: 0.08601410686969757\n",
      "Epoch 150/300, Loss: 0.08388172319302192\n",
      "Epoch 151/300, Loss: 0.08488268175950417\n",
      "Epoch 152/300, Loss: 0.0842744054702612\n",
      "Epoch 153/300, Loss: 0.0852342826815752\n",
      "Epoch 154/300, Loss: 0.08413388780676402\n",
      "Epoch 155/300, Loss: 0.08522279560565948\n",
      "Epoch 156/300, Loss: 0.08475650617709526\n",
      "Epoch 157/300, Loss: 0.0840694119150822\n",
      "Epoch 158/300, Loss: 0.08499479523071876\n",
      "Epoch 159/300, Loss: 0.08411023020744324\n",
      "Epoch 160/300, Loss: 0.08523066169940509\n",
      "Epoch 161/300, Loss: 0.0841760990711359\n",
      "Epoch 162/300, Loss: 0.0838069090476403\n",
      "Epoch 163/300, Loss: 0.08414806310947125\n",
      "Epoch 164/300, Loss: 0.08439484238624573\n",
      "Epoch 165/300, Loss: 0.08539106811468418\n",
      "Epoch 166/300, Loss: 0.0840025796340062\n",
      "Epoch 167/300, Loss: 0.08472026483370708\n",
      "Epoch 168/300, Loss: 0.08533419468081914\n",
      "Epoch 169/300, Loss: 0.08476029279140326\n",
      "Epoch 170/300, Loss: 0.08452202952825107\n",
      "Epoch 171/300, Loss: 0.08387775547229327\n",
      "Epoch 172/300, Loss: 0.08422037557913707\n",
      "Epoch 173/300, Loss: 0.08496150947534122\n",
      "Epoch 174/300, Loss: 0.08383947553542945\n",
      "Epoch 175/300, Loss: 0.08476111579399842\n",
      "Epoch 176/300, Loss: 0.08440777888664833\n",
      "Epoch 177/300, Loss: 0.08527470494692142\n",
      "Epoch 178/300, Loss: 0.08422681803886707\n",
      "Epoch 179/300, Loss: 0.08480751227874023\n",
      "Epoch 180/300, Loss: 0.08529751461285812\n",
      "Epoch 181/300, Loss: 0.0839425388437051\n",
      "Epoch 182/300, Loss: 0.08449312414114292\n",
      "Epoch 183/300, Loss: 0.08495332931096737\n",
      "Epoch 184/300, Loss: 0.08383514617498104\n",
      "Epoch 185/300, Loss: 0.08542539207981183\n",
      "Epoch 186/300, Loss: 0.0848818553181795\n",
      "Epoch 187/300, Loss: 0.08409287723211142\n",
      "Epoch 188/300, Loss: 0.08453905295867187\n",
      "Epoch 189/300, Loss: 0.08499864546152261\n",
      "Epoch 190/300, Loss: 0.08477474519839653\n",
      "Epoch 191/300, Loss: 0.08420003262849954\n",
      "Epoch 192/300, Loss: 0.08463505655527115\n",
      "Epoch 193/300, Loss: 0.0843346703511018\n",
      "Epoch 194/300, Loss: 0.08412828697608067\n",
      "Epoch 195/300, Loss: 0.0837749896141199\n",
      "Epoch 196/300, Loss: 0.08369994220825341\n",
      "Epoch 197/300, Loss: 0.08467739820480347\n",
      "Epoch 198/300, Loss: 0.08531486042417012\n",
      "Epoch 199/300, Loss: 0.08481222906937966\n",
      "Epoch 200/300, Loss: 0.08413363534670609\n",
      "Epoch 201/300, Loss: 0.08503617575535408\n",
      "Epoch 202/300, Loss: 0.08437594198263608\n",
      "Epoch 203/300, Loss: 0.08345803045309506\n",
      "Epoch 204/300, Loss: 0.08475985664587754\n",
      "Epoch 205/300, Loss: 0.08473925808301339\n",
      "Epoch 206/300, Loss: 0.08472931213103808\n",
      "Epoch 207/300, Loss: 0.08354578597041276\n",
      "Epoch 208/300, Loss: 0.08422899933961722\n",
      "Epoch 209/300, Loss: 0.08457463521223801\n",
      "Epoch 210/300, Loss: 0.08472388295026925\n",
      "Epoch 211/300, Loss: 0.08404326840088917\n",
      "Epoch 212/300, Loss: 0.0847728825532473\n",
      "Epoch 213/300, Loss: 0.08465550438715862\n",
      "Epoch 214/300, Loss: 0.08423065623411766\n",
      "Epoch 215/300, Loss: 0.08504628733946727\n",
      "Epoch 216/300, Loss: 0.08456515979308349\n",
      "Epoch 217/300, Loss: 0.08490745608623211\n",
      "Epoch 218/300, Loss: 0.08451139697661766\n",
      "Epoch 219/300, Loss: 0.08528713480784343\n",
      "Epoch 220/300, Loss: 0.08422853109928277\n",
      "Epoch 221/300, Loss: 0.08490433200047566\n",
      "Epoch 222/300, Loss: 0.08440018789126323\n",
      "Epoch 223/300, Loss: 0.08365584623355132\n",
      "Epoch 224/300, Loss: 0.08396473756203285\n",
      "Epoch 225/300, Loss: 0.0837529507967142\n",
      "Epoch 226/300, Loss: 0.08470904712493603\n",
      "Epoch 227/300, Loss: 0.08548422100452277\n",
      "Epoch 228/300, Loss: 0.08533766177984384\n",
      "Epoch 229/300, Loss: 0.08474447291630965\n",
      "Epoch 230/300, Loss: 0.08440734274112262\n",
      "Epoch 231/300, Loss: 0.08370805961581376\n",
      "Epoch 232/300, Loss: 0.0844275916998203\n",
      "Epoch 233/300, Loss: 0.08439451914567214\n",
      "Epoch 234/300, Loss: 0.08528898427119622\n",
      "Epoch 235/300, Loss: 0.08493730884331924\n",
      "Epoch 236/300, Loss: 0.08390438040861717\n",
      "Epoch 237/300, Loss: 0.08420740870329049\n",
      "Epoch 238/300, Loss: 0.08503527194261551\n",
      "Epoch 239/300, Loss: 0.0841980565052766\n",
      "Epoch 240/300, Loss: 0.08487878109400089\n",
      "Epoch 241/300, Loss: 0.08508436553753339\n",
      "Epoch 242/300, Loss: 0.08461277186870575\n",
      "Epoch 243/300, Loss: 0.08389635441394952\n",
      "Epoch 244/300, Loss: 0.08437648874062759\n",
      "Epoch 245/300, Loss: 0.08514076471328735\n",
      "Epoch 246/300, Loss: 0.08489006700424048\n",
      "Epoch 247/300, Loss: 0.0849980517075612\n",
      "Epoch 248/300, Loss: 0.0839533330156253\n",
      "Epoch 249/300, Loss: 0.08393789713199322\n",
      "Epoch 250/300, Loss: 0.08494455539263211\n",
      "Epoch 251/300, Loss: 0.08374904411343428\n",
      "Epoch 252/300, Loss: 0.08528616279363632\n",
      "Epoch 253/300, Loss: 0.08498096064879344\n",
      "Epoch 254/300, Loss: 0.08552694091430077\n",
      "Epoch 255/300, Loss: 0.08522709401754233\n",
      "Epoch 256/300, Loss: 0.08462980905404457\n",
      "Epoch 257/300, Loss: 0.08393762661860539\n",
      "Epoch 258/300, Loss: 0.0841430018727596\n",
      "Epoch 259/300, Loss: 0.08527210584053627\n",
      "Epoch 260/300, Loss: 0.08455408994968121\n",
      "Epoch 261/300, Loss: 0.08545878500892566\n",
      "Epoch 262/300, Loss: 0.0844132940356548\n",
      "Epoch 263/300, Loss: 0.08408708985035236\n",
      "Epoch 264/300, Loss: 0.08496239666755383\n",
      "Epoch 265/300, Loss: 0.08451281487941742\n",
      "Epoch 266/300, Loss: 0.08482137723610951\n",
      "Epoch 267/300, Loss: 0.0846334111232024\n",
      "Epoch 268/300, Loss: 0.08458591424501859\n",
      "Epoch 269/300, Loss: 0.08465434324282867\n",
      "Epoch 270/300, Loss: 0.08429096008722599\n",
      "Epoch 271/300, Loss: 0.08533926336811139\n",
      "Epoch 272/300, Loss: 0.08444562840920228\n",
      "Epoch 273/300, Loss: 0.0854064472592794\n",
      "Epoch 274/300, Loss: 0.08431776326436263\n",
      "Epoch 275/300, Loss: 0.08425566439445202\n",
      "Epoch 276/300, Loss: 0.08522256119893147\n",
      "Epoch 277/300, Loss: 0.08577725291252136\n",
      "Epoch 278/300, Loss: 0.08470982714341237\n",
      "Epoch 279/300, Loss: 0.08467371532550225\n",
      "Epoch 280/300, Loss: 0.08415752190809983\n",
      "Epoch 281/300, Loss: 0.08466768150146191\n",
      "Epoch 282/300, Loss: 0.0844835965679242\n",
      "Epoch 283/300, Loss: 0.08530147660237092\n",
      "Epoch 284/300, Loss: 0.08401211752341343\n",
      "Epoch 285/300, Loss: 0.0841284033197623\n",
      "Epoch 286/300, Loss: 0.08418474174462832\n",
      "Epoch 287/300, Loss: 0.08515265870552796\n",
      "Epoch 288/300, Loss: 0.08518200998122875\n",
      "Epoch 289/300, Loss: 0.08397449037203422\n",
      "Epoch 290/300, Loss: 0.08457094946732888\n",
      "Epoch 291/300, Loss: 0.0850874982201136\n",
      "Epoch 292/300, Loss: 0.0842355598623936\n",
      "Epoch 293/300, Loss: 0.08419576115333118\n",
      "Epoch 294/300, Loss: 0.08524081798700187\n",
      "Epoch 295/300, Loss: 0.0835619164774051\n",
      "Epoch 296/300, Loss: 0.08458397136284755\n",
      "Epoch 297/300, Loss: 0.08439767761872365\n",
      "Epoch 298/300, Loss: 0.08521989389107777\n",
      "Epoch 299/300, Loss: 0.08423905074596405\n",
      "Epoch 300/300, Loss: 0.08419455587863922\n",
      "Average Test Loss: 0.09865104034543037\n",
      "R2 Score: -0.00294688633228235\n",
      "Fold 2/5\n",
      "Epoch 1/300, Loss: 0.4736473743732159\n",
      "Epoch 2/300, Loss: 0.4303023333732898\n",
      "Epoch 3/300, Loss: 0.39732641210922826\n",
      "Epoch 4/300, Loss: 0.3606684368390303\n",
      "Epoch 5/300, Loss: 0.31766176109130567\n",
      "Epoch 6/300, Loss: 0.28383002831385684\n",
      "Epoch 7/300, Loss: 0.24588027137976426\n",
      "Epoch 8/300, Loss: 0.2155303404881404\n",
      "Epoch 9/300, Loss: 0.18211993288535339\n",
      "Epoch 10/300, Loss: 0.15373685612128332\n",
      "Epoch 11/300, Loss: 0.13344293202345187\n",
      "Epoch 12/300, Loss: 0.11523176099245365\n",
      "Epoch 13/300, Loss: 0.10303879242676955\n",
      "Epoch 14/300, Loss: 0.09566946900807895\n",
      "Epoch 15/300, Loss: 0.09008370167933978\n",
      "Epoch 16/300, Loss: 0.08858170532263242\n",
      "Epoch 17/300, Loss: 0.08694991010885972\n",
      "Epoch 18/300, Loss: 0.08629193615454894\n",
      "Epoch 19/300, Loss: 0.08607334414353737\n",
      "Epoch 20/300, Loss: 0.0859611934194198\n",
      "Epoch 21/300, Loss: 0.08595998585224152\n",
      "Epoch 22/300, Loss: 0.08571745799137996\n",
      "Epoch 23/300, Loss: 0.08631701079698709\n",
      "Epoch 24/300, Loss: 0.08581146941735195\n",
      "Epoch 25/300, Loss: 0.08591010306890194\n",
      "Epoch 26/300, Loss: 0.08500373936616458\n",
      "Epoch 27/300, Loss: 0.08507595727076897\n",
      "Epoch 28/300, Loss: 0.08576008792106922\n",
      "Epoch 29/300, Loss: 0.08600872640426342\n",
      "Epoch 30/300, Loss: 0.08597346452566293\n",
      "Epoch 31/300, Loss: 0.084857967037421\n",
      "Epoch 32/300, Loss: 0.08391444213115253\n",
      "Epoch 33/300, Loss: 0.08501689193340448\n",
      "Epoch 34/300, Loss: 0.08446931151243356\n",
      "Epoch 35/300, Loss: 0.08464848336118919\n",
      "Epoch 36/300, Loss: 0.08568941629849948\n",
      "Epoch 37/300, Loss: 0.08493617750131167\n",
      "Epoch 38/300, Loss: 0.08430732901279743\n",
      "Epoch 39/300, Loss: 0.08493915830667202\n",
      "Epoch 40/300, Loss: 0.08445110974403527\n",
      "Epoch 41/300, Loss: 0.08481181126374465\n",
      "Epoch 42/300, Loss: 0.08519560098648071\n",
      "Epoch 43/300, Loss: 0.08544176301130882\n",
      "Epoch 44/300, Loss: 0.08434141885775787\n",
      "Epoch 45/300, Loss: 0.08490467644654788\n",
      "Epoch 46/300, Loss: 0.08458790412315956\n",
      "Epoch 47/300, Loss: 0.08467361159049548\n",
      "Epoch 48/300, Loss: 0.08412847782556827\n",
      "Epoch 49/300, Loss: 0.08512108199871503\n",
      "Epoch 50/300, Loss: 0.08450752725967994\n",
      "Epoch 51/300, Loss: 0.08466464567642945\n",
      "Epoch 52/300, Loss: 0.08419058299981631\n",
      "Epoch 53/300, Loss: 0.08479000341433746\n",
      "Epoch 54/300, Loss: 0.0854754837659689\n",
      "Epoch 55/300, Loss: 0.0839079750271944\n",
      "Epoch 56/300, Loss: 0.08470336233194058\n",
      "Epoch 57/300, Loss: 0.0845367770928603\n",
      "Epoch 58/300, Loss: 0.08464378462387966\n",
      "Epoch 59/300, Loss: 0.08470886200666428\n",
      "Epoch 60/300, Loss: 0.08448113099886821\n",
      "Epoch 61/300, Loss: 0.08470183782852612\n",
      "Epoch 62/300, Loss: 0.08395348145411564\n",
      "Epoch 63/300, Loss: 0.084472289452186\n",
      "Epoch 64/300, Loss: 0.08481215112484418\n",
      "Epoch 65/300, Loss: 0.08440125962862602\n",
      "Epoch 66/300, Loss: 0.08451184401145348\n",
      "Epoch 67/300, Loss: 0.08523781253741337\n",
      "Epoch 68/300, Loss: 0.08531905768009332\n",
      "Epoch 69/300, Loss: 0.08426981018139766\n",
      "Epoch 70/300, Loss: 0.0842734374679052\n",
      "Epoch 71/300, Loss: 0.08440296753094746\n",
      "Epoch 72/300, Loss: 0.08444506503068484\n",
      "Epoch 73/300, Loss: 0.0841801384320626\n",
      "Epoch 74/300, Loss: 0.08524096871797855\n",
      "Epoch 75/300, Loss: 0.08465978331290759\n",
      "Epoch 76/300, Loss: 0.08360136758822662\n",
      "Epoch 77/300, Loss: 0.08412263485101554\n",
      "Epoch 78/300, Loss: 0.08335013802234943\n",
      "Epoch 79/300, Loss: 0.08597491796200092\n",
      "Epoch 80/300, Loss: 0.08399258324733147\n",
      "Epoch 81/300, Loss: 0.08452952309296681\n",
      "Epoch 82/300, Loss: 0.08340128568502572\n",
      "Epoch 83/300, Loss: 0.08453077937547977\n",
      "Epoch 84/300, Loss: 0.083939240528987\n",
      "Epoch 85/300, Loss: 0.08482673649604504\n",
      "Epoch 86/300, Loss: 0.0842309261743839\n",
      "Epoch 87/300, Loss: 0.0844134848851424\n",
      "Epoch 88/300, Loss: 0.08502185058135253\n",
      "Epoch 89/300, Loss: 0.08379647938104776\n",
      "Epoch 90/300, Loss: 0.08416765527083324\n",
      "Epoch 91/300, Loss: 0.08470495102497247\n",
      "Epoch 92/300, Loss: 0.08483024887167491\n",
      "Epoch 93/300, Loss: 0.08418249740050389\n",
      "Epoch 94/300, Loss: 0.08531151969845478\n",
      "Epoch 95/300, Loss: 0.08583102948390521\n",
      "Epoch 96/300, Loss: 0.08436703051512058\n",
      "Epoch 97/300, Loss: 0.08458569359320861\n",
      "Epoch 98/300, Loss: 0.08457140968396114\n",
      "Epoch 99/300, Loss: 0.08456037594721867\n",
      "Epoch 100/300, Loss: 0.08424058212683751\n",
      "Epoch 101/300, Loss: 0.08420660461370762\n",
      "Epoch 102/300, Loss: 0.08525438549426886\n",
      "Epoch 103/300, Loss: 0.08448065186922367\n",
      "Epoch 104/300, Loss: 0.08468400572354977\n",
      "Epoch 105/300, Loss: 0.08452704491523597\n",
      "Epoch 106/300, Loss: 0.08499248555073372\n",
      "Epoch 107/300, Loss: 0.08379141699809295\n",
      "Epoch 108/300, Loss: 0.08501592966226432\n",
      "Epoch 109/300, Loss: 0.0852166677896793\n",
      "Epoch 110/300, Loss: 0.0850638156900039\n",
      "Epoch 111/300, Loss: 0.08484253459251843\n",
      "Epoch 112/300, Loss: 0.08517248899890827\n",
      "Epoch 113/300, Loss: 0.08347109447305019\n",
      "Epoch 114/300, Loss: 0.08528353503117195\n",
      "Epoch 115/300, Loss: 0.08438087713259917\n",
      "Epoch 116/300, Loss: 0.08437301218509674\n",
      "Epoch 117/300, Loss: 0.08491501212120056\n",
      "Epoch 118/300, Loss: 0.08433522312686993\n",
      "Epoch 119/300, Loss: 0.08462499769834372\n",
      "Epoch 120/300, Loss: 0.08404593055064861\n",
      "Epoch 121/300, Loss: 0.08303123999100465\n",
      "Epoch 122/300, Loss: 0.08499311139950386\n",
      "Epoch 123/300, Loss: 0.08349257306410716\n",
      "Epoch 124/300, Loss: 0.08350318039839084\n",
      "Epoch 125/300, Loss: 0.08387302836546531\n",
      "Epoch 126/300, Loss: 0.08380238883770429\n",
      "Epoch 127/300, Loss: 0.08372367918491364\n",
      "Epoch 128/300, Loss: 0.08409401373221324\n",
      "Epoch 129/300, Loss: 0.08373806281731679\n",
      "Epoch 130/300, Loss: 0.08492663158820225\n",
      "Epoch 131/300, Loss: 0.0839346102797068\n",
      "Epoch 132/300, Loss: 0.08363198890135838\n",
      "Epoch 133/300, Loss: 0.08515054961809745\n",
      "Epoch 134/300, Loss: 0.08463375270366669\n",
      "Epoch 135/300, Loss: 0.08393301872106698\n",
      "Epoch 136/300, Loss: 0.08447133291226167\n",
      "Epoch 137/300, Loss: 0.08378273191360328\n",
      "Epoch 138/300, Loss: 0.08459205524279521\n",
      "Epoch 139/300, Loss: 0.08455708508308117\n",
      "Epoch 140/300, Loss: 0.0846974838238496\n",
      "Epoch 141/300, Loss: 0.08410624042153358\n",
      "Epoch 142/300, Loss: 0.08408940124970216\n",
      "Epoch 143/300, Loss: 0.08398534472172077\n",
      "Epoch 144/300, Loss: 0.08493498827402408\n",
      "Epoch 145/300, Loss: 0.08491850529725735\n",
      "Epoch 146/300, Loss: 0.08475740311237481\n",
      "Epoch 147/300, Loss: 0.08462678067959271\n",
      "Epoch 148/300, Loss: 0.08349732252267691\n",
      "Epoch 149/300, Loss: 0.0843033750469868\n",
      "Epoch 150/300, Loss: 0.08431974339943665\n",
      "Epoch 151/300, Loss: 0.08396865198245415\n",
      "Epoch 152/300, Loss: 0.08399698539422108\n",
      "Epoch 153/300, Loss: 0.08396584425981228\n",
      "Epoch 154/300, Loss: 0.08464483658854778\n",
      "Epoch 155/300, Loss: 0.08380006425655805\n",
      "Epoch 156/300, Loss: 0.0845643373636099\n",
      "Epoch 157/300, Loss: 0.08388361048239928\n",
      "Epoch 158/300, Loss: 0.08438247900742751\n",
      "Epoch 159/300, Loss: 0.08371526690629813\n",
      "Epoch 160/300, Loss: 0.08432497829198837\n",
      "Epoch 161/300, Loss: 0.08456358714745595\n",
      "Epoch 162/300, Loss: 0.08382890144219765\n",
      "Epoch 163/300, Loss: 0.08464073160519966\n",
      "Epoch 164/300, Loss: 0.08436531344285378\n",
      "Epoch 165/300, Loss: 0.08405863207120162\n",
      "Epoch 166/300, Loss: 0.08460022566410211\n",
      "Epoch 167/300, Loss: 0.08441247848364022\n",
      "Epoch 168/300, Loss: 0.08399630681826518\n",
      "Epoch 169/300, Loss: 0.08387937052891804\n",
      "Epoch 170/300, Loss: 0.08418768758957203\n",
      "Epoch 171/300, Loss: 0.0842486247420311\n",
      "Epoch 172/300, Loss: 0.08492849251398674\n",
      "Epoch 173/300, Loss: 0.0839547893175712\n",
      "Epoch 174/300, Loss: 0.08361597072619659\n",
      "Epoch 175/300, Loss: 0.08411275767363034\n",
      "Epoch 176/300, Loss: 0.08441175176547124\n",
      "Epoch 177/300, Loss: 0.0848444075538562\n",
      "Epoch 178/300, Loss: 0.08400284498929977\n",
      "Epoch 179/300, Loss: 0.08402197292217842\n",
      "Epoch 180/300, Loss: 0.08500586965909371\n",
      "Epoch 181/300, Loss: 0.08460668187875015\n",
      "Epoch 182/300, Loss: 0.08370830749089901\n",
      "Epoch 183/300, Loss: 0.084474248954883\n",
      "Epoch 184/300, Loss: 0.08431100329527488\n",
      "Epoch 185/300, Loss: 0.08433594153477596\n",
      "Epoch 186/300, Loss: 0.08513436581079777\n",
      "Epoch 187/300, Loss: 0.08502522827341007\n",
      "Epoch 188/300, Loss: 0.08384600969461295\n",
      "Epoch 189/300, Loss: 0.08511656150221825\n",
      "Epoch 190/300, Loss: 0.08387303409668115\n",
      "Epoch 191/300, Loss: 0.08459252921434549\n",
      "Epoch 192/300, Loss: 0.08461499443420997\n",
      "Epoch 193/300, Loss: 0.08474946767091751\n",
      "Epoch 194/300, Loss: 0.08450579872498146\n",
      "Epoch 195/300, Loss: 0.08393222895952371\n",
      "Epoch 196/300, Loss: 0.08408237592532085\n",
      "Epoch 197/300, Loss: 0.08385886825048007\n",
      "Epoch 198/300, Loss: 0.08446597881042041\n",
      "Epoch 199/300, Loss: 0.08459634792346221\n",
      "Epoch 200/300, Loss: 0.08438631605643493\n",
      "Epoch 201/300, Loss: 0.08438496062388787\n",
      "Epoch 202/300, Loss: 0.08358797946801552\n",
      "Epoch 203/300, Loss: 0.08419087758431068\n",
      "Epoch 204/300, Loss: 0.08366774996885887\n",
      "Epoch 205/300, Loss: 0.0847423724257029\n",
      "Epoch 206/300, Loss: 0.08384221620284595\n",
      "Epoch 207/300, Loss: 0.08300809963391377\n",
      "Epoch 208/300, Loss: 0.08332691227014248\n",
      "Epoch 209/300, Loss: 0.08434065603292905\n",
      "Epoch 210/300, Loss: 0.08365668127169976\n",
      "Epoch 211/300, Loss: 0.08421820917954811\n",
      "Epoch 212/300, Loss: 0.08405610116628501\n",
      "Epoch 213/300, Loss: 0.08347893219727737\n",
      "Epoch 214/300, Loss: 0.08455360050384815\n",
      "Epoch 215/300, Loss: 0.08473708881781651\n",
      "Epoch 216/300, Loss: 0.08521317060177143\n",
      "Epoch 217/300, Loss: 0.08498545392201497\n",
      "Epoch 218/300, Loss: 0.08403024535912734\n",
      "Epoch 219/300, Loss: 0.08403994658818612\n",
      "Epoch 220/300, Loss: 0.08397939801216125\n",
      "Epoch 221/300, Loss: 0.08440693754416245\n",
      "Epoch 222/300, Loss: 0.08388741944844906\n",
      "Epoch 223/300, Loss: 0.08558192447974132\n",
      "Epoch 224/300, Loss: 0.0840205865410658\n",
      "Epoch 225/300, Loss: 0.08407954241220768\n",
      "Epoch 226/300, Loss: 0.0849421018591294\n",
      "Epoch 227/300, Loss: 0.08422982234221238\n",
      "Epoch 228/300, Loss: 0.0842709203179066\n",
      "Epoch 229/300, Loss: 0.08460825796310718\n",
      "Epoch 230/300, Loss: 0.08410989607755955\n",
      "Epoch 231/300, Loss: 0.0840568536749253\n",
      "Epoch 232/300, Loss: 0.08464841487315986\n",
      "Epoch 233/300, Loss: 0.08423653646157338\n",
      "Epoch 234/300, Loss: 0.08394606755330013\n",
      "Epoch 235/300, Loss: 0.08357225301174018\n",
      "Epoch 236/300, Loss: 0.08509850960511428\n",
      "Epoch 237/300, Loss: 0.08384730666875839\n",
      "Epoch 238/300, Loss: 0.08420487665213071\n",
      "Epoch 239/300, Loss: 0.0845814524934842\n",
      "Epoch 240/300, Loss: 0.08437987531606968\n",
      "Epoch 241/300, Loss: 0.0839562381689365\n",
      "Epoch 242/300, Loss: 0.08534424121563251\n",
      "Epoch 243/300, Loss: 0.08348373954112713\n",
      "Epoch 244/300, Loss: 0.0843084127857135\n",
      "Epoch 245/300, Loss: 0.08456064474124175\n",
      "Epoch 246/300, Loss: 0.0843633057979437\n",
      "Epoch 247/300, Loss: 0.08487122104718135\n",
      "Epoch 248/300, Loss: 0.08357686520769046\n",
      "Epoch 249/300, Loss: 0.08418587022102796\n",
      "Epoch 250/300, Loss: 0.08449485095647666\n",
      "Epoch 251/300, Loss: 0.08437799433102974\n",
      "Epoch 252/300, Loss: 0.08471878331441146\n",
      "Epoch 253/300, Loss: 0.0848022080384768\n",
      "Epoch 254/300, Loss: 0.08423724140112217\n",
      "Epoch 255/300, Loss: 0.08419212584312145\n",
      "Epoch 256/300, Loss: 0.08449257509066509\n",
      "Epoch 257/300, Loss: 0.08468354665316068\n",
      "Epoch 258/300, Loss: 0.08408718269604903\n",
      "Epoch 259/300, Loss: 0.08424500662546891\n",
      "Epoch 260/300, Loss: 0.08512342205414405\n",
      "Epoch 261/300, Loss: 0.08350766593447098\n",
      "Epoch 262/300, Loss: 0.08394088939978527\n",
      "Epoch 263/300, Loss: 0.08471828469863305\n",
      "Epoch 264/300, Loss: 0.08452900785666245\n",
      "Epoch 265/300, Loss: 0.08426997524041396\n",
      "Epoch 266/300, Loss: 0.08404846947926742\n",
      "Epoch 267/300, Loss: 0.0839214135821049\n",
      "Epoch 268/300, Loss: 0.08420955676298875\n",
      "Epoch 269/300, Loss: 0.08420928682272251\n",
      "Epoch 270/300, Loss: 0.08453621314122127\n",
      "Epoch 271/300, Loss: 0.08480882014219578\n",
      "Epoch 272/300, Loss: 0.0851807972559562\n",
      "Epoch 273/300, Loss: 0.08478746792444816\n",
      "Epoch 274/300, Loss: 0.08433341521483201\n",
      "Epoch 275/300, Loss: 0.08418988780333446\n",
      "Epoch 276/300, Loss: 0.08506637811660767\n",
      "Epoch 277/300, Loss: 0.08554694686944668\n",
      "Epoch 278/300, Loss: 0.08411083026574208\n",
      "Epoch 279/300, Loss: 0.0842862742451521\n",
      "Epoch 280/300, Loss: 0.08470834734348151\n",
      "Epoch 281/300, Loss: 0.0847280415204855\n",
      "Epoch 282/300, Loss: 0.08404446335939261\n",
      "Epoch 283/300, Loss: 0.08376342459366871\n",
      "Epoch 284/300, Loss: 0.08433762593911244\n",
      "Epoch 285/300, Loss: 0.08361929139265648\n",
      "Epoch 286/300, Loss: 0.08502275897906376\n",
      "Epoch 287/300, Loss: 0.08461721241474152\n",
      "Epoch 288/300, Loss: 0.08389071890941033\n",
      "Epoch 289/300, Loss: 0.0844791978597641\n",
      "Epoch 290/300, Loss: 0.08403922846684089\n",
      "Epoch 291/300, Loss: 0.08422769606113434\n",
      "Epoch 292/300, Loss: 0.08443215145514561\n",
      "Epoch 293/300, Loss: 0.08530281025629777\n",
      "Epoch 294/300, Loss: 0.08439319122296113\n",
      "Epoch 295/300, Loss: 0.08471226864136182\n",
      "Epoch 296/300, Loss: 0.08427168600834332\n",
      "Epoch 297/300, Loss: 0.08424846426798747\n",
      "Epoch 298/300, Loss: 0.08466447030122463\n",
      "Epoch 299/300, Loss: 0.0847310211796027\n",
      "Epoch 300/300, Loss: 0.08442665407290825\n",
      "Average Test Loss: 0.08463324047625065\n",
      "R2 Score: -0.010798337132647662\n",
      "Fold 3/5\n",
      "Epoch 1/300, Loss: 0.10093701516206448\n",
      "Epoch 2/300, Loss: 0.09414364053652836\n",
      "Epoch 3/300, Loss: 0.09136867809754151\n",
      "Epoch 4/300, Loss: 0.08967504421105751\n",
      "Epoch 5/300, Loss: 0.08812794719751064\n",
      "Epoch 6/300, Loss: 0.0864074625647985\n",
      "Epoch 7/300, Loss: 0.08546662502563916\n",
      "Epoch 8/300, Loss: 0.08454921268499814\n",
      "Epoch 9/300, Loss: 0.08539154380559921\n",
      "Epoch 10/300, Loss: 0.08449139847205235\n",
      "Epoch 11/300, Loss: 0.08512395677658227\n",
      "Epoch 12/300, Loss: 0.08573147253348277\n",
      "Epoch 13/300, Loss: 0.08465134581694236\n",
      "Epoch 14/300, Loss: 0.08533209504989478\n",
      "Epoch 15/300, Loss: 0.08494659455922934\n",
      "Epoch 16/300, Loss: 0.08433173023737393\n",
      "Epoch 17/300, Loss: 0.08560980913730767\n",
      "Epoch 18/300, Loss: 0.08523518764055692\n",
      "Epoch 19/300, Loss: 0.08543756145697373\n",
      "Epoch 20/300, Loss: 0.08476057304785801\n",
      "Epoch 21/300, Loss: 0.08458924236205909\n",
      "Epoch 22/300, Loss: 0.0847145003768114\n",
      "Epoch 23/300, Loss: 0.08450275487624682\n",
      "Epoch 24/300, Loss: 0.08416706552872291\n",
      "Epoch 25/300, Loss: 0.08556908999498074\n",
      "Epoch 26/300, Loss: 0.08464865558422528\n",
      "Epoch 27/300, Loss: 0.08420599366609867\n",
      "Epoch 28/300, Loss: 0.08517022717457551\n",
      "Epoch 29/300, Loss: 0.08504582483034867\n",
      "Epoch 30/300, Loss: 0.08560844281545052\n",
      "Epoch 31/300, Loss: 0.08458806918217586\n",
      "Epoch 32/300, Loss: 0.08544740883203653\n",
      "Epoch 33/300, Loss: 0.08537531701418069\n",
      "Epoch 34/300, Loss: 0.0841028684606919\n",
      "Epoch 35/300, Loss: 0.08442043054562348\n",
      "Epoch 36/300, Loss: 0.08436998094503696\n",
      "Epoch 37/300, Loss: 0.08427617985468644\n",
      "Epoch 38/300, Loss: 0.08490532808578931\n",
      "Epoch 39/300, Loss: 0.08485789654346612\n",
      "Epoch 40/300, Loss: 0.08437785334312\n",
      "Epoch 41/300, Loss: 0.08471173219955884\n",
      "Epoch 42/300, Loss: 0.0845236056126081\n",
      "Epoch 43/300, Loss: 0.08473390168868579\n",
      "Epoch 44/300, Loss: 0.08512263114635761\n",
      "Epoch 45/300, Loss: 0.0840057094509785\n",
      "Epoch 46/300, Loss: 0.08407961691801365\n",
      "Epoch 47/300, Loss: 0.08519101257507618\n",
      "Epoch 48/300, Loss: 0.08457489254382941\n",
      "Epoch 49/300, Loss: 0.0846657409117772\n",
      "Epoch 50/300, Loss: 0.08415480359242512\n",
      "Epoch 51/300, Loss: 0.08494127369843997\n",
      "Epoch 52/300, Loss: 0.08475129363628534\n",
      "Epoch 53/300, Loss: 0.08401323568362457\n",
      "Epoch 54/300, Loss: 0.08494042032040082\n",
      "Epoch 55/300, Loss: 0.08340676873922348\n",
      "Epoch 56/300, Loss: 0.08380333735392644\n",
      "Epoch 57/300, Loss: 0.08418587939097331\n",
      "Epoch 58/300, Loss: 0.08363406532085858\n",
      "Epoch 59/300, Loss: 0.0838109002663539\n",
      "Epoch 60/300, Loss: 0.08372197701380803\n",
      "Epoch 61/300, Loss: 0.08462106321866696\n",
      "Epoch 62/300, Loss: 0.08479691182191555\n",
      "Epoch 63/300, Loss: 0.08399591021812879\n",
      "Epoch 64/300, Loss: 0.0834166155411647\n",
      "Epoch 65/300, Loss: 0.08453175941338906\n",
      "Epoch 66/300, Loss: 0.08506413549184799\n",
      "Epoch 67/300, Loss: 0.08392941493254441\n",
      "Epoch 68/300, Loss: 0.08380172516290958\n",
      "Epoch 69/300, Loss: 0.08286746534017417\n",
      "Epoch 70/300, Loss: 0.08442583393592101\n",
      "Epoch 71/300, Loss: 0.08378057926893234\n",
      "Epoch 72/300, Loss: 0.08377525898126456\n",
      "Epoch 73/300, Loss: 0.08357510543786563\n",
      "Epoch 74/300, Loss: 0.08383996383501933\n",
      "Epoch 75/300, Loss: 0.08425522079834571\n",
      "Epoch 76/300, Loss: 0.08304389222310139\n",
      "Epoch 77/300, Loss: 0.08306082882560216\n",
      "Epoch 78/300, Loss: 0.08369372727779242\n",
      "Epoch 79/300, Loss: 0.08314555883407593\n",
      "Epoch 80/300, Loss: 0.08461978573065537\n",
      "Epoch 81/300, Loss: 0.08388226307355441\n",
      "Epoch 82/300, Loss: 0.08329229171459492\n",
      "Epoch 83/300, Loss: 0.08405556243199569\n",
      "Epoch 84/300, Loss: 0.0845846889110712\n",
      "Epoch 85/300, Loss: 0.08343430952383922\n",
      "Epoch 86/300, Loss: 0.0836476070376543\n",
      "Epoch 87/300, Loss: 0.08369297648851688\n",
      "Epoch 88/300, Loss: 0.08449571350446114\n",
      "Epoch 89/300, Loss: 0.08373536398777595\n",
      "Epoch 90/300, Loss: 0.08375338407663199\n",
      "Epoch 91/300, Loss: 0.0844438964357743\n",
      "Epoch 92/300, Loss: 0.08421578086339511\n",
      "Epoch 93/300, Loss: 0.08471947449904221\n",
      "Epoch 94/300, Loss: 0.08289655756491882\n",
      "Epoch 95/300, Loss: 0.08378903625103143\n",
      "Epoch 96/300, Loss: 0.08421453776267859\n",
      "Epoch 97/300, Loss: 0.08361245405215484\n",
      "Epoch 98/300, Loss: 0.08346932037518574\n",
      "Epoch 99/300, Loss: 0.0837940453336789\n",
      "Epoch 100/300, Loss: 0.08315064184940778\n",
      "Epoch 101/300, Loss: 0.08395077975896689\n",
      "Epoch 102/300, Loss: 0.08348353264423516\n",
      "Epoch 103/300, Loss: 0.08307439833879471\n",
      "Epoch 104/300, Loss: 0.0834104923101572\n",
      "Epoch 105/300, Loss: 0.08313120500399516\n",
      "Epoch 106/300, Loss: 0.08321793090838653\n",
      "Epoch 107/300, Loss: 0.08327149083981147\n",
      "Epoch 108/300, Loss: 0.08338241909558956\n",
      "Epoch 109/300, Loss: 0.08326382361925565\n",
      "Epoch 110/300, Loss: 0.08329905340304741\n",
      "Epoch 111/300, Loss: 0.0840545789553569\n",
      "Epoch 112/300, Loss: 0.08344984856935647\n",
      "Epoch 113/300, Loss: 0.08381326210040313\n",
      "Epoch 114/300, Loss: 0.08369663185798205\n",
      "Epoch 115/300, Loss: 0.08314738193383583\n",
      "Epoch 116/300, Loss: 0.08333681065302628\n",
      "Epoch 117/300, Loss: 0.08432868466927455\n",
      "Epoch 118/300, Loss: 0.08328306617645118\n",
      "Epoch 119/300, Loss: 0.08360808457319553\n",
      "Epoch 120/300, Loss: 0.08366710635331961\n",
      "Epoch 121/300, Loss: 0.08425512737952746\n",
      "Epoch 122/300, Loss: 0.08284765653885327\n",
      "Epoch 123/300, Loss: 0.08410343814354676\n",
      "Epoch 124/300, Loss: 0.08314027923804063\n",
      "Epoch 125/300, Loss: 0.08342979447199748\n",
      "Epoch 126/300, Loss: 0.0832755806354376\n",
      "Epoch 127/300, Loss: 0.08327102890381446\n",
      "Epoch 128/300, Loss: 0.08325573515433532\n",
      "Epoch 129/300, Loss: 0.08399027299422485\n",
      "Epoch 130/300, Loss: 0.08334996436650936\n",
      "Epoch 131/300, Loss: 0.08395186066627502\n",
      "Epoch 132/300, Loss: 0.08325179035847004\n",
      "Epoch 133/300, Loss: 0.08236026420043065\n",
      "Epoch 134/300, Loss: 0.08311887429310726\n",
      "Epoch 135/300, Loss: 0.08300839823025924\n",
      "Epoch 136/300, Loss: 0.0836402361209576\n",
      "Epoch 137/300, Loss: 0.08359560542381726\n",
      "Epoch 138/300, Loss: 0.0835213684118711\n",
      "Epoch 139/300, Loss: 0.08271923661231995\n",
      "Epoch 140/300, Loss: 0.0834743523826966\n",
      "Epoch 141/300, Loss: 0.0824935522217017\n",
      "Epoch 142/300, Loss: 0.08367722481489182\n",
      "Epoch 143/300, Loss: 0.0832827532520661\n",
      "Epoch 144/300, Loss: 0.08314939874869126\n",
      "Epoch 145/300, Loss: 0.08273511036084248\n",
      "Epoch 146/300, Loss: 0.0831433442922739\n",
      "Epoch 147/300, Loss: 0.0832673253921362\n",
      "Epoch 148/300, Loss: 0.08290843550975506\n",
      "Epoch 149/300, Loss: 0.08336247045260209\n",
      "Epoch 150/300, Loss: 0.08284119717203654\n",
      "Epoch 151/300, Loss: 0.08289318474439475\n",
      "Epoch 152/300, Loss: 0.08324328981913053\n",
      "Epoch 153/300, Loss: 0.08353145993672885\n",
      "Epoch 154/300, Loss: 0.08418511255429341\n",
      "Epoch 155/300, Loss: 0.08332267690163392\n",
      "Epoch 156/300, Loss: 0.08270625254282585\n",
      "Epoch 157/300, Loss: 0.08250352912224256\n",
      "Epoch 158/300, Loss: 0.0829936357644888\n",
      "Epoch 159/300, Loss: 0.08333759067150262\n",
      "Epoch 160/300, Loss: 0.08241828989524108\n",
      "Epoch 161/300, Loss: 0.0831684613457093\n",
      "Epoch 162/300, Loss: 0.08264931577902573\n",
      "Epoch 163/300, Loss: 0.08236526182064643\n",
      "Epoch 164/300, Loss: 0.08268656467015927\n",
      "Epoch 165/300, Loss: 0.08317279643737353\n",
      "Epoch 166/300, Loss: 0.08246454252646519\n",
      "Epoch 167/300, Loss: 0.08287011831998825\n",
      "Epoch 168/300, Loss: 0.08239715145184444\n",
      "Epoch 169/300, Loss: 0.08290937485603186\n",
      "Epoch 170/300, Loss: 0.08321141680845848\n",
      "Epoch 171/300, Loss: 0.08285265989028491\n",
      "Epoch 172/300, Loss: 0.08371353149414062\n",
      "Epoch 173/300, Loss: 0.08338118516481839\n",
      "Epoch 174/300, Loss: 0.0825852075448403\n",
      "Epoch 175/300, Loss: 0.08262082934379578\n",
      "Epoch 176/300, Loss: 0.08263800121270694\n",
      "Epoch 177/300, Loss: 0.08270187274767803\n",
      "Epoch 178/300, Loss: 0.08233174395102721\n",
      "Epoch 179/300, Loss: 0.0827608727491819\n",
      "Epoch 180/300, Loss: 0.08349953993008687\n",
      "Epoch 181/300, Loss: 0.08239885075734212\n",
      "Epoch 182/300, Loss: 0.08283200688087024\n",
      "Epoch 183/300, Loss: 0.08283673054896869\n",
      "Epoch 184/300, Loss: 0.08297785887351403\n",
      "Epoch 185/300, Loss: 0.0824328322823231\n",
      "Epoch 186/300, Loss: 0.08301925487243213\n",
      "Epoch 187/300, Loss: 0.08231030175319085\n",
      "Epoch 188/300, Loss: 0.08234941443571678\n",
      "Epoch 189/300, Loss: 0.08302037647137275\n",
      "Epoch 190/300, Loss: 0.08270951990897839\n",
      "Epoch 191/300, Loss: 0.08313611379036537\n",
      "Epoch 192/300, Loss: 0.08267807616637303\n",
      "Epoch 193/300, Loss: 0.08341316936107782\n",
      "Epoch 194/300, Loss: 0.0830193689236274\n",
      "Epoch 195/300, Loss: 0.08323449813402616\n",
      "Epoch 196/300, Loss: 0.08208562376407477\n",
      "Epoch 197/300, Loss: 0.08165175152512696\n",
      "Epoch 198/300, Loss: 0.08263119539389244\n",
      "Epoch 199/300, Loss: 0.08314569810262093\n",
      "Epoch 200/300, Loss: 0.0829273508145259\n",
      "Epoch 201/300, Loss: 0.08337736530945851\n",
      "Epoch 202/300, Loss: 0.08268873221599139\n",
      "Epoch 203/300, Loss: 0.08327968762471126\n",
      "Epoch 204/300, Loss: 0.08232499257876323\n",
      "Epoch 205/300, Loss: 0.08282962527412635\n",
      "Epoch 206/300, Loss: 0.08331621552889164\n",
      "Epoch 207/300, Loss: 0.0824329314323572\n",
      "Epoch 208/300, Loss: 0.08249539308823071\n",
      "Epoch 209/300, Loss: 0.0822442569411718\n",
      "Epoch 210/300, Loss: 0.08294024433080967\n",
      "Epoch 211/300, Loss: 0.08306902303145482\n",
      "Epoch 212/300, Loss: 0.08313067314716485\n",
      "Epoch 213/300, Loss: 0.08362657806048027\n",
      "Epoch 214/300, Loss: 0.08288145753053519\n",
      "Epoch 215/300, Loss: 0.0818265567605312\n",
      "Epoch 216/300, Loss: 0.08223493282611553\n",
      "Epoch 217/300, Loss: 0.08333574923185202\n",
      "Epoch 218/300, Loss: 0.08103945220892246\n",
      "Epoch 219/300, Loss: 0.08285278683671585\n",
      "Epoch 220/300, Loss: 0.08327942914687671\n",
      "Epoch 221/300, Loss: 0.0830322142976981\n",
      "Epoch 222/300, Loss: 0.08242198882194665\n",
      "Epoch 223/300, Loss: 0.08207748887630609\n",
      "Epoch 224/300, Loss: 0.08281974150584294\n",
      "Epoch 225/300, Loss: 0.08287775287261376\n",
      "Epoch 226/300, Loss: 0.08240297981179677\n",
      "Epoch 227/300, Loss: 0.08207155821415094\n",
      "Epoch 228/300, Loss: 0.08263170432585937\n",
      "Epoch 229/300, Loss: 0.08246084761161071\n",
      "Epoch 230/300, Loss: 0.08250307062497506\n",
      "Epoch 231/300, Loss: 0.08264537614125472\n",
      "Epoch 232/300, Loss: 0.08280479564116551\n",
      "Epoch 233/300, Loss: 0.08232890184109028\n",
      "Epoch 234/300, Loss: 0.08302130951331212\n",
      "Epoch 235/300, Loss: 0.08316418585868982\n",
      "Epoch 236/300, Loss: 0.08273724008065003\n",
      "Epoch 237/300, Loss: 0.08226175033129178\n",
      "Epoch 238/300, Loss: 0.08226807186236748\n",
      "Epoch 239/300, Loss: 0.0829121212546642\n",
      "Epoch 240/300, Loss: 0.08249365538358688\n",
      "Epoch 241/300, Loss: 0.08297807952532402\n",
      "Epoch 242/300, Loss: 0.08262462512804912\n",
      "Epoch 243/300, Loss: 0.08204251871659206\n",
      "Epoch 244/300, Loss: 0.08313850313425064\n",
      "Epoch 245/300, Loss: 0.08242956663553531\n",
      "Epoch 246/300, Loss: 0.0829665964612594\n",
      "Epoch 247/300, Loss: 0.08259214288913287\n",
      "Epoch 248/300, Loss: 0.08255786047532009\n",
      "Epoch 249/300, Loss: 0.08274651548037162\n",
      "Epoch 250/300, Loss: 0.08221838336724502\n",
      "Epoch 251/300, Loss: 0.08259204775094986\n",
      "Epoch 252/300, Loss: 0.08242866912713417\n",
      "Epoch 253/300, Loss: 0.08305782137008813\n",
      "Epoch 254/300, Loss: 0.0826748598080415\n",
      "Epoch 255/300, Loss: 0.08263192039269668\n",
      "Epoch 256/300, Loss: 0.08187755139974448\n",
      "Epoch 257/300, Loss: 0.08166302339388774\n",
      "Epoch 258/300, Loss: 0.08302427312502494\n",
      "Epoch 259/300, Loss: 0.08212302338618499\n",
      "Epoch 260/300, Loss: 0.08294901309105066\n",
      "Epoch 261/300, Loss: 0.08241841827447598\n",
      "Epoch 262/300, Loss: 0.08199418221528713\n",
      "Epoch 263/300, Loss: 0.08301440282509877\n",
      "Epoch 264/300, Loss: 0.08222288237168239\n",
      "Epoch 265/300, Loss: 0.08291396269431481\n",
      "Epoch 266/300, Loss: 0.08287649257824971\n",
      "Epoch 267/300, Loss: 0.08252004648630436\n",
      "Epoch 268/300, Loss: 0.08259812226662269\n",
      "Epoch 269/300, Loss: 0.08278858547027294\n",
      "Epoch 270/300, Loss: 0.08181157593543713\n",
      "Epoch 271/300, Loss: 0.08290552978332226\n",
      "Epoch 272/300, Loss: 0.08268624085646409\n",
      "Epoch 273/300, Loss: 0.08253806313643089\n",
      "Epoch 274/300, Loss: 0.08269350746503243\n",
      "Epoch 275/300, Loss: 0.08309026864858773\n",
      "Epoch 276/300, Loss: 0.08293561866650215\n",
      "Epoch 277/300, Loss: 0.08298365370585369\n",
      "Epoch 278/300, Loss: 0.08166875747533944\n",
      "Epoch 279/300, Loss: 0.0822406944174033\n",
      "Epoch 280/300, Loss: 0.08327039503134213\n",
      "Epoch 281/300, Loss: 0.08212357816787866\n",
      "Epoch 282/300, Loss: 0.08274739751448998\n",
      "Epoch 283/300, Loss: 0.08271166452994713\n",
      "Epoch 284/300, Loss: 0.0822307880108173\n",
      "Epoch 285/300, Loss: 0.08271331340074539\n",
      "Epoch 286/300, Loss: 0.08290744744814359\n",
      "Epoch 287/300, Loss: 0.08278400508257058\n",
      "Epoch 288/300, Loss: 0.08234243725354855\n",
      "Epoch 289/300, Loss: 0.08232271642639087\n",
      "Epoch 290/300, Loss: 0.0831210997242194\n",
      "Epoch 291/300, Loss: 0.08344003500846717\n",
      "Epoch 292/300, Loss: 0.08290501397389632\n",
      "Epoch 293/300, Loss: 0.08233198065024155\n",
      "Epoch 294/300, Loss: 0.08241596588721642\n",
      "Epoch 295/300, Loss: 0.08264596531024346\n",
      "Epoch 296/300, Loss: 0.08246985192482288\n",
      "Epoch 297/300, Loss: 0.0824515876861719\n",
      "Epoch 298/300, Loss: 0.08197782819087689\n",
      "Epoch 299/300, Loss: 0.08205137029290199\n",
      "Epoch 300/300, Loss: 0.08309977730879417\n",
      "Average Test Loss: 0.08434442803263664\n",
      "R2 Score: -0.011895741864537346\n",
      "Fold 4/5\n",
      "Epoch 1/300, Loss: 1.105034901545598\n",
      "Epoch 2/300, Loss: 1.0388775146924532\n",
      "Epoch 3/300, Loss: 0.9870523672837478\n",
      "Epoch 4/300, Loss: 0.9221035242080688\n",
      "Epoch 5/300, Loss: 0.865083382679866\n",
      "Epoch 6/300, Loss: 0.8153731364470261\n",
      "Epoch 7/300, Loss: 0.7635011948071994\n",
      "Epoch 8/300, Loss: 0.7166553277235764\n",
      "Epoch 9/300, Loss: 0.6668343498156621\n",
      "Epoch 10/300, Loss: 0.622103370152987\n",
      "Epoch 11/300, Loss: 0.5727713451935694\n",
      "Epoch 12/300, Loss: 0.5318178030160757\n",
      "Epoch 13/300, Loss: 0.4913573975746448\n",
      "Epoch 14/300, Loss: 0.45484597178605884\n",
      "Epoch 15/300, Loss: 0.41910051841002244\n",
      "Epoch 16/300, Loss: 0.38837867287489086\n",
      "Epoch 17/300, Loss: 0.3709247433222257\n",
      "Epoch 18/300, Loss: 0.3544165881780478\n",
      "Epoch 19/300, Loss: 0.34253546595573425\n",
      "Epoch 20/300, Loss: 0.3300582583133991\n",
      "Epoch 21/300, Loss: 0.3214952189188737\n",
      "Epoch 22/300, Loss: 0.31338522869807023\n",
      "Epoch 23/300, Loss: 0.3030585084970181\n",
      "Epoch 24/300, Loss: 0.2996438420735873\n",
      "Epoch 25/300, Loss: 0.2887883186340332\n",
      "Epoch 26/300, Loss: 0.282087293954996\n",
      "Epoch 27/300, Loss: 0.27320894369712245\n",
      "Epoch 28/300, Loss: 0.2663303464651108\n",
      "Epoch 29/300, Loss: 0.25869917754943555\n",
      "Epoch 30/300, Loss: 0.2534279376268387\n",
      "Epoch 31/300, Loss: 0.24411966365117294\n",
      "Epoch 32/300, Loss: 0.23659369349479675\n",
      "Epoch 33/300, Loss: 0.23281993315770075\n",
      "Epoch 34/300, Loss: 0.2258667372740232\n",
      "Epoch 35/300, Loss: 0.22066830098628998\n",
      "Epoch 36/300, Loss: 0.21552273974968836\n",
      "Epoch 37/300, Loss: 0.20992901577399328\n",
      "Epoch 38/300, Loss: 0.2024271316253222\n",
      "Epoch 39/300, Loss: 0.19865433527873114\n",
      "Epoch 40/300, Loss: 0.19335801097062918\n",
      "Epoch 41/300, Loss: 0.18884469110232133\n",
      "Epoch 42/300, Loss: 0.18244068553814521\n",
      "Epoch 43/300, Loss: 0.1785808985049908\n",
      "Epoch 44/300, Loss: 0.17458018431296715\n",
      "Epoch 45/300, Loss: 0.1700344727589534\n",
      "Epoch 46/300, Loss: 0.16546392784668848\n",
      "Epoch 47/300, Loss: 0.16156693834524888\n",
      "Epoch 48/300, Loss: 0.16088334012490052\n",
      "Epoch 49/300, Loss: 0.15630447749908155\n",
      "Epoch 50/300, Loss: 0.15332176249760848\n",
      "Epoch 51/300, Loss: 0.149254628098928\n",
      "Epoch 52/300, Loss: 0.14610748107616717\n",
      "Epoch 53/300, Loss: 0.14230507554916236\n",
      "Epoch 54/300, Loss: 0.1409901724411891\n",
      "Epoch 55/300, Loss: 0.13736880054840675\n",
      "Epoch 56/300, Loss: 0.13449489497221434\n",
      "Epoch 57/300, Loss: 0.13225366461735505\n",
      "Epoch 58/300, Loss: 0.13080646498845175\n",
      "Epoch 59/300, Loss: 0.12700133999952903\n",
      "Epoch 60/300, Loss: 0.12479122040363458\n",
      "Epoch 61/300, Loss: 0.12381769258242387\n",
      "Epoch 62/300, Loss: 0.11990204338844006\n",
      "Epoch 63/300, Loss: 0.11856973629731399\n",
      "Epoch 64/300, Loss: 0.11832882234683403\n",
      "Epoch 65/300, Loss: 0.11596402697838269\n",
      "Epoch 66/300, Loss: 0.11365029101188366\n",
      "Epoch 67/300, Loss: 0.11206486591925988\n",
      "Epoch 68/300, Loss: 0.11255007638381077\n",
      "Epoch 69/300, Loss: 0.10774381229510674\n",
      "Epoch 70/300, Loss: 0.10809059498401788\n",
      "Epoch 71/300, Loss: 0.10688840540555808\n",
      "Epoch 72/300, Loss: 0.10562976621664487\n",
      "Epoch 73/300, Loss: 0.10369670219146289\n",
      "Epoch 74/300, Loss: 0.10315171285317494\n",
      "Epoch 75/300, Loss: 0.10295875370502472\n",
      "Epoch 76/300, Loss: 0.1017062532214018\n",
      "Epoch 77/300, Loss: 0.10059988555999902\n",
      "Epoch 78/300, Loss: 0.09956052268926914\n",
      "Epoch 79/300, Loss: 0.09907335501450759\n",
      "Epoch 80/300, Loss: 0.09753486628715809\n",
      "Epoch 81/300, Loss: 0.09735515484443077\n",
      "Epoch 82/300, Loss: 0.09667078806803776\n",
      "Epoch 83/300, Loss: 0.09636999380130035\n",
      "Epoch 84/300, Loss: 0.09593306539150384\n",
      "Epoch 85/300, Loss: 0.0952844636944624\n",
      "Epoch 86/300, Loss: 0.09502480179071426\n",
      "Epoch 87/300, Loss: 0.0931589465874892\n",
      "Epoch 88/300, Loss: 0.09302757737728265\n",
      "Epoch 89/300, Loss: 0.09245019463392404\n",
      "Epoch 90/300, Loss: 0.09167672063295658\n",
      "Epoch 91/300, Loss: 0.09191014503057186\n",
      "Epoch 92/300, Loss: 0.09139066476088303\n",
      "Epoch 93/300, Loss: 0.09089796187785956\n",
      "Epoch 94/300, Loss: 0.09121136997754757\n",
      "Epoch 95/300, Loss: 0.08988984960776109\n",
      "Epoch 96/300, Loss: 0.09105418507869427\n",
      "Epoch 97/300, Loss: 0.09030271436159427\n",
      "Epoch 98/300, Loss: 0.09015333308623387\n",
      "Epoch 99/300, Loss: 0.08933222924287502\n",
      "Epoch 100/300, Loss: 0.0902795149729802\n",
      "Epoch 101/300, Loss: 0.09000733208197814\n",
      "Epoch 102/300, Loss: 0.09005289524793625\n",
      "Epoch 103/300, Loss: 0.08903283568528983\n",
      "Epoch 104/300, Loss: 0.08936029901871315\n",
      "Epoch 105/300, Loss: 0.0891799324980149\n",
      "Epoch 106/300, Loss: 0.08858222399766628\n",
      "Epoch 107/300, Loss: 0.08816694697508445\n",
      "Epoch 108/300, Loss: 0.08795973200064439\n",
      "Epoch 109/300, Loss: 0.08878924754949716\n",
      "Epoch 110/300, Loss: 0.08881668116037662\n",
      "Epoch 111/300, Loss: 0.08782331588176581\n",
      "Epoch 112/300, Loss: 0.08807335392786907\n",
      "Epoch 113/300, Loss: 0.08817580399604943\n",
      "Epoch 114/300, Loss: 0.08874113112688065\n",
      "Epoch 115/300, Loss: 0.08720273581834939\n",
      "Epoch 116/300, Loss: 0.08817849193628018\n",
      "Epoch 117/300, Loss: 0.0878625437617302\n",
      "Epoch 118/300, Loss: 0.08685289380642083\n",
      "Epoch 119/300, Loss: 0.08928355058798423\n",
      "Epoch 120/300, Loss: 0.08759428503421637\n",
      "Epoch 121/300, Loss: 0.08726578091199581\n",
      "Epoch 122/300, Loss: 0.08761546302300233\n",
      "Epoch 123/300, Loss: 0.0866494972545367\n",
      "Epoch 124/300, Loss: 0.08715000175512753\n",
      "Epoch 125/300, Loss: 0.08866311380496392\n",
      "Epoch 126/300, Loss: 0.08756406318682891\n",
      "Epoch 127/300, Loss: 0.08763236839037675\n",
      "Epoch 128/300, Loss: 0.08694826983488523\n",
      "Epoch 129/300, Loss: 0.08745173622782414\n",
      "Epoch 130/300, Loss: 0.08791597015582599\n",
      "Epoch 131/300, Loss: 0.08850362954231408\n",
      "Epoch 132/300, Loss: 0.08735945362311143\n",
      "Epoch 133/300, Loss: 0.0882015056335009\n",
      "Epoch 134/300, Loss: 0.08820185753015372\n",
      "Epoch 135/300, Loss: 0.08710168187434857\n",
      "Epoch 136/300, Loss: 0.08793454789198361\n",
      "Epoch 137/300, Loss: 0.08782858630785575\n",
      "Epoch 138/300, Loss: 0.08727048280147406\n",
      "Epoch 139/300, Loss: 0.08748109352130157\n",
      "Epoch 140/300, Loss: 0.08795342537072989\n",
      "Epoch 141/300, Loss: 0.08797296021993344\n",
      "Epoch 142/300, Loss: 0.08693999911730106\n",
      "Epoch 143/300, Loss: 0.0868555548099371\n",
      "Epoch 144/300, Loss: 0.08703840638582523\n",
      "Epoch 145/300, Loss: 0.08721122948022988\n",
      "Epoch 146/300, Loss: 0.08757199289707038\n",
      "Epoch 147/300, Loss: 0.08711730173000923\n",
      "Epoch 148/300, Loss: 0.0870833620429039\n",
      "Epoch 149/300, Loss: 0.08750365044061954\n",
      "Epoch 150/300, Loss: 0.08723390732820217\n",
      "Epoch 151/300, Loss: 0.08844075351953506\n",
      "Epoch 152/300, Loss: 0.08724886178970337\n",
      "Epoch 153/300, Loss: 0.0868414520071103\n",
      "Epoch 154/300, Loss: 0.08699270223195736\n",
      "Epoch 155/300, Loss: 0.08851200800675613\n",
      "Epoch 156/300, Loss: 0.087814283485596\n",
      "Epoch 157/300, Loss: 0.08763149036810948\n",
      "Epoch 158/300, Loss: 0.08746879834395188\n",
      "Epoch 159/300, Loss: 0.08742033690214157\n",
      "Epoch 160/300, Loss: 0.08709893547571622\n",
      "Epoch 161/300, Loss: 0.08688841588222064\n",
      "Epoch 162/300, Loss: 0.08695054971254788\n",
      "Epoch 163/300, Loss: 0.08748078632813233\n",
      "Epoch 164/300, Loss: 0.08775279900202385\n",
      "Epoch 165/300, Loss: 0.08731792122125626\n",
      "Epoch 166/300, Loss: 0.08850031747267796\n",
      "Epoch 167/300, Loss: 0.08751135777968627\n",
      "Epoch 168/300, Loss: 0.08659645972343591\n",
      "Epoch 169/300, Loss: 0.08767396039687671\n",
      "Epoch 170/300, Loss: 0.08701728857480563\n",
      "Epoch 171/300, Loss: 0.08681911917833182\n",
      "Epoch 172/300, Loss: 0.08723209855648187\n",
      "Epoch 173/300, Loss: 0.08722505259972352\n",
      "Epoch 174/300, Loss: 0.0869859577371524\n",
      "Epoch 175/300, Loss: 0.08829835114570764\n",
      "Epoch 176/300, Loss: 0.08823263129362693\n",
      "Epoch 177/300, Loss: 0.08738226386216971\n",
      "Epoch 178/300, Loss: 0.08725438209680411\n",
      "Epoch 179/300, Loss: 0.08721339473357567\n",
      "Epoch 180/300, Loss: 0.08763783597029172\n",
      "Epoch 181/300, Loss: 0.0873061275252929\n",
      "Epoch 182/300, Loss: 0.08790850811279736\n",
      "Epoch 183/300, Loss: 0.08726526281008354\n",
      "Epoch 184/300, Loss: 0.08736915313280545\n",
      "Epoch 185/300, Loss: 0.08712107573564236\n",
      "Epoch 186/300, Loss: 0.08649646032315034\n",
      "Epoch 187/300, Loss: 0.0871966309272326\n",
      "Epoch 188/300, Loss: 0.08723500485603626\n",
      "Epoch 189/300, Loss: 0.08734677388117863\n",
      "Epoch 190/300, Loss: 0.08807538793637203\n",
      "Epoch 191/300, Loss: 0.08705322043253826\n",
      "Epoch 192/300, Loss: 0.08795745613483283\n",
      "Epoch 193/300, Loss: 0.08678593314610995\n",
      "Epoch 194/300, Loss: 0.08755501359701157\n",
      "Epoch 195/300, Loss: 0.08731138820831592\n",
      "Epoch 196/300, Loss: 0.08704594236153823\n",
      "Epoch 197/300, Loss: 0.08805825503972861\n",
      "Epoch 198/300, Loss: 0.08715553123217362\n",
      "Epoch 199/300, Loss: 0.0878398441351377\n",
      "Epoch 200/300, Loss: 0.08737613432682477\n",
      "Epoch 201/300, Loss: 0.08696323747818287\n",
      "Epoch 202/300, Loss: 0.08724306810360688\n",
      "Epoch 203/300, Loss: 0.08777125924825668\n",
      "Epoch 204/300, Loss: 0.08783938449162704\n",
      "Epoch 205/300, Loss: 0.08696512706004657\n",
      "Epoch 206/300, Loss: 0.08744389105301636\n",
      "Epoch 207/300, Loss: 0.08747694870600334\n",
      "Epoch 208/300, Loss: 0.08775325807241294\n",
      "Epoch 209/300, Loss: 0.08733770365898426\n",
      "Epoch 210/300, Loss: 0.0870648381801752\n",
      "Epoch 211/300, Loss: 0.08722012146161152\n",
      "Epoch 212/300, Loss: 0.0877662616280409\n",
      "Epoch 213/300, Loss: 0.0878281696484639\n",
      "Epoch 214/300, Loss: 0.08694231510162354\n",
      "Epoch 215/300, Loss: 0.08742781212696663\n",
      "Epoch 216/300, Loss: 0.0877838318164532\n",
      "Epoch 217/300, Loss: 0.08804954703037556\n",
      "Epoch 218/300, Loss: 0.08747380398786984\n",
      "Epoch 219/300, Loss: 0.0875432462646411\n",
      "Epoch 220/300, Loss: 0.08650153015668575\n",
      "Epoch 221/300, Loss: 0.08772321389271663\n",
      "Epoch 222/300, Loss: 0.08683975212849103\n",
      "Epoch 223/300, Loss: 0.08672160196762818\n",
      "Epoch 224/300, Loss: 0.08723004047687237\n",
      "Epoch 225/300, Loss: 0.08760575205087662\n",
      "Epoch 226/300, Loss: 0.08759506505269271\n",
      "Epoch 227/300, Loss: 0.087670427102309\n",
      "Epoch 228/300, Loss: 0.08662061966382541\n",
      "Epoch 229/300, Loss: 0.0876046923490671\n",
      "Epoch 230/300, Loss: 0.08718670847324225\n",
      "Epoch 231/300, Loss: 0.08791663096501277\n",
      "Epoch 232/300, Loss: 0.08749065433557217\n",
      "Epoch 233/300, Loss: 0.08653075878436749\n",
      "Epoch 234/300, Loss: 0.0877505810214923\n",
      "Epoch 235/300, Loss: 0.08680679878363243\n",
      "Epoch 236/300, Loss: 0.08659545962627117\n",
      "Epoch 237/300, Loss: 0.08693758226357974\n",
      "Epoch 238/300, Loss: 0.08746281438148938\n",
      "Epoch 239/300, Loss: 0.08658362179994583\n",
      "Epoch 240/300, Loss: 0.08682729303836823\n",
      "Epoch 241/300, Loss: 0.08848066456042804\n",
      "Epoch 242/300, Loss: 0.08796479896857189\n",
      "Epoch 243/300, Loss: 0.08718682940189655\n",
      "Epoch 244/300, Loss: 0.08815492288424419\n",
      "Epoch 245/300, Loss: 0.08713563302388558\n",
      "Epoch 246/300, Loss: 0.08644132316112518\n",
      "Epoch 247/300, Loss: 0.0875537905555505\n",
      "Epoch 248/300, Loss: 0.08861183948241748\n",
      "Epoch 249/300, Loss: 0.08690879780512589\n",
      "Epoch 250/300, Loss: 0.08684800679867084\n",
      "Epoch 251/300, Loss: 0.0868378860446123\n",
      "Epoch 252/300, Loss: 0.08689051751907055\n",
      "Epoch 253/300, Loss: 0.08763614153632751\n",
      "Epoch 254/300, Loss: 0.08791389774817687\n",
      "Epoch 255/300, Loss: 0.08803328699790515\n",
      "Epoch 256/300, Loss: 0.08779824066620606\n",
      "Epoch 257/300, Loss: 0.08682172516217598\n",
      "Epoch 258/300, Loss: 0.08739641595345277\n",
      "Epoch 259/300, Loss: 0.08777204213234094\n",
      "Epoch 260/300, Loss: 0.0883247170310754\n",
      "Epoch 261/300, Loss: 0.08646443486213684\n",
      "Epoch 262/300, Loss: 0.08724069910553786\n",
      "Epoch 263/300, Loss: 0.08785599985947976\n",
      "Epoch 264/300, Loss: 0.08780469974646202\n",
      "Epoch 265/300, Loss: 0.08784967832840405\n",
      "Epoch 266/300, Loss: 0.08676433162047313\n",
      "Epoch 267/300, Loss: 0.08721345605758521\n",
      "Epoch 268/300, Loss: 0.08746567884316811\n",
      "Epoch 269/300, Loss: 0.08725937685141197\n",
      "Epoch 270/300, Loss: 0.0875183051595321\n",
      "Epoch 271/300, Loss: 0.08730310258957055\n",
      "Epoch 272/300, Loss: 0.08759715637335411\n",
      "Epoch 273/300, Loss: 0.08715398838886848\n",
      "Epoch 274/300, Loss: 0.08696640454805814\n",
      "Epoch 275/300, Loss: 0.0875682423894222\n",
      "Epoch 276/300, Loss: 0.08749524790507096\n",
      "Epoch 277/300, Loss: 0.08745131125816932\n",
      "Epoch 278/300, Loss: 0.0881201120523306\n",
      "Epoch 279/300, Loss: 0.08657810607781777\n",
      "Epoch 280/300, Loss: 0.08772628869001682\n",
      "Epoch 281/300, Loss: 0.0864434098968139\n",
      "Epoch 282/300, Loss: 0.08829574516186348\n",
      "Epoch 283/300, Loss: 0.08736007947188157\n",
      "Epoch 284/300, Loss: 0.08712618454144551\n",
      "Epoch 285/300, Loss: 0.08744952369194764\n",
      "Epoch 286/300, Loss: 0.08702888569006553\n",
      "Epoch 287/300, Loss: 0.08797802833410409\n",
      "Epoch 288/300, Loss: 0.0872617237843\n",
      "Epoch 289/300, Loss: 0.08740874723746227\n",
      "Epoch 290/300, Loss: 0.08773996852911435\n",
      "Epoch 291/300, Loss: 0.08673458259839278\n",
      "Epoch 292/300, Loss: 0.08616876516204613\n",
      "Epoch 293/300, Loss: 0.08763390779495239\n",
      "Epoch 294/300, Loss: 0.08730613669523826\n",
      "Epoch 295/300, Loss: 0.08676357567310333\n",
      "Epoch 296/300, Loss: 0.0884240733889433\n",
      "Epoch 297/300, Loss: 0.08792226303082246\n",
      "Epoch 298/300, Loss: 0.0874345342700298\n",
      "Epoch 299/300, Loss: 0.08678853225249511\n",
      "Epoch 300/300, Loss: 0.08671257301018788\n",
      "Average Test Loss: 0.0786262433975935\n",
      "R2 Score: -0.008944043280057379\n",
      "Fold 5/5\n",
      "Epoch 1/300, Loss: 0.08687373021474251\n",
      "Epoch 2/300, Loss: 0.0854173583480028\n",
      "Epoch 3/300, Loss: 0.08528290517055072\n",
      "Epoch 4/300, Loss: 0.08456071351583187\n",
      "Epoch 5/300, Loss: 0.08486019991911374\n",
      "Epoch 6/300, Loss: 0.08425667509436607\n",
      "Epoch 7/300, Loss: 0.08486828953027725\n",
      "Epoch 8/300, Loss: 0.0848450494500307\n",
      "Epoch 9/300, Loss: 0.08405427749340351\n",
      "Epoch 10/300, Loss: 0.08468920622880642\n",
      "Epoch 11/300, Loss: 0.08529002219438553\n",
      "Epoch 12/300, Loss: 0.08465617150068283\n",
      "Epoch 13/300, Loss: 0.08413389840951332\n",
      "Epoch 14/300, Loss: 0.08406912650053318\n",
      "Epoch 15/300, Loss: 0.08525393731318988\n",
      "Epoch 16/300, Loss: 0.08344317256258084\n",
      "Epoch 17/300, Loss: 0.08406161688841306\n",
      "Epoch 18/300, Loss: 0.08491646613066013\n",
      "Epoch 19/300, Loss: 0.08458034694194794\n",
      "Epoch 20/300, Loss: 0.08475686495120709\n",
      "Epoch 21/300, Loss: 0.08435123585737668\n",
      "Epoch 22/300, Loss: 0.08412307099654125\n",
      "Epoch 23/300, Loss: 0.08460166534552208\n",
      "Epoch 24/300, Loss: 0.0853499758702058\n",
      "Epoch 25/300, Loss: 0.0847119648869221\n",
      "Epoch 26/300, Loss: 0.08525586070922705\n",
      "Epoch 27/300, Loss: 0.08433669289717308\n",
      "Epoch 28/300, Loss: 0.0836186116704574\n",
      "Epoch 29/300, Loss: 0.084005346091894\n",
      "Epoch 30/300, Loss: 0.08393932764346783\n",
      "Epoch 31/300, Loss: 0.08414206080711804\n",
      "Epoch 32/300, Loss: 0.0836856491290606\n",
      "Epoch 33/300, Loss: 0.08316233066412118\n",
      "Epoch 34/300, Loss: 0.08387080751932584\n",
      "Epoch 35/300, Loss: 0.08505713939666748\n",
      "Epoch 36/300, Loss: 0.08417115131249794\n",
      "Epoch 37/300, Loss: 0.08373670795789132\n",
      "Epoch 38/300, Loss: 0.08383156416507867\n",
      "Epoch 39/300, Loss: 0.08268885142528094\n",
      "Epoch 40/300, Loss: 0.08359232315650353\n",
      "Epoch 41/300, Loss: 0.08320087194442749\n",
      "Epoch 42/300, Loss: 0.08283278346061707\n",
      "Epoch 43/300, Loss: 0.083363016637472\n",
      "Epoch 44/300, Loss: 0.08379285094829705\n",
      "Epoch 45/300, Loss: 0.08333259878250268\n",
      "Epoch 46/300, Loss: 0.08303432567761494\n",
      "Epoch 47/300, Loss: 0.08294346183538437\n",
      "Epoch 48/300, Loss: 0.08369887276337697\n",
      "Epoch 49/300, Loss: 0.08389549587781613\n",
      "Epoch 50/300, Loss: 0.0843703901538482\n",
      "Epoch 51/300, Loss: 0.08373152350003903\n",
      "Epoch 52/300, Loss: 0.08314910817604798\n",
      "Epoch 53/300, Loss: 0.08307374268770218\n",
      "Epoch 54/300, Loss: 0.08305901403610523\n",
      "Epoch 55/300, Loss: 0.08357937863239875\n",
      "Epoch 56/300, Loss: 0.08345452065651233\n",
      "Epoch 57/300, Loss: 0.08278511865780903\n",
      "Epoch 58/300, Loss: 0.0826055292899792\n",
      "Epoch 59/300, Loss: 0.08274264060533963\n",
      "Epoch 60/300, Loss: 0.08307018188329843\n",
      "Epoch 61/300, Loss: 0.08307890192820476\n",
      "Epoch 62/300, Loss: 0.08313482827865161\n",
      "Epoch 63/300, Loss: 0.0838630606348698\n",
      "Epoch 64/300, Loss: 0.08259088030228248\n",
      "Epoch 65/300, Loss: 0.08330348305977307\n",
      "Epoch 66/300, Loss: 0.08273588579434615\n",
      "Epoch 67/300, Loss: 0.0824945202240577\n",
      "Epoch 68/300, Loss: 0.08317563969355363\n",
      "Epoch 69/300, Loss: 0.08339369354339746\n",
      "Epoch 70/300, Loss: 0.08270982595590445\n",
      "Epoch 71/300, Loss: 0.08333319712143678\n",
      "Epoch 72/300, Loss: 0.08379007302797757\n",
      "Epoch 73/300, Loss: 0.08283811005262229\n",
      "Epoch 74/300, Loss: 0.08219441083761361\n",
      "Epoch 75/300, Loss: 0.0826030304798713\n",
      "Epoch 76/300, Loss: 0.08272061955470306\n",
      "Epoch 77/300, Loss: 0.08309691284711544\n",
      "Epoch 78/300, Loss: 0.08327018641508542\n",
      "Epoch 79/300, Loss: 0.08239029233272259\n",
      "Epoch 80/300, Loss: 0.08215021342039108\n",
      "Epoch 81/300, Loss: 0.08221128869515199\n",
      "Epoch 82/300, Loss: 0.08267226242102109\n",
      "Epoch 83/300, Loss: 0.08289749633807403\n",
      "Epoch 84/300, Loss: 0.08257024391339375\n",
      "Epoch 85/300, Loss: 0.08269509042684849\n",
      "Epoch 86/300, Loss: 0.08134220368587054\n",
      "Epoch 87/300, Loss: 0.08279803452583459\n",
      "Epoch 88/300, Loss: 0.08311009464355615\n",
      "Epoch 89/300, Loss: 0.08260370045900345\n",
      "Epoch 90/300, Loss: 0.08229047461197926\n",
      "Epoch 91/300, Loss: 0.08229089757570854\n",
      "Epoch 92/300, Loss: 0.08177710611086625\n",
      "Epoch 93/300, Loss: 0.08226330692951496\n",
      "Epoch 94/300, Loss: 0.08305216809877983\n",
      "Epoch 95/300, Loss: 0.0833642018529085\n",
      "Epoch 96/300, Loss: 0.0832176019365971\n",
      "Epoch 97/300, Loss: 0.08272606535599782\n",
      "Epoch 98/300, Loss: 0.08283515274524689\n",
      "Epoch 99/300, Loss: 0.08249443941391431\n",
      "Epoch 100/300, Loss: 0.08258770176997551\n",
      "Epoch 101/300, Loss: 0.08225303487135814\n",
      "Epoch 102/300, Loss: 0.0822478452554116\n",
      "Epoch 103/300, Loss: 0.08321538510230872\n",
      "Epoch 104/300, Loss: 0.08271923718544152\n",
      "Epoch 105/300, Loss: 0.0825071340570083\n",
      "Epoch 106/300, Loss: 0.08319502381178048\n",
      "Epoch 107/300, Loss: 0.0827001528098033\n",
      "Epoch 108/300, Loss: 0.08176318899943279\n",
      "Epoch 109/300, Loss: 0.08212630336101238\n",
      "Epoch 110/300, Loss: 0.08223637078817074\n",
      "Epoch 111/300, Loss: 0.08300618426157878\n",
      "Epoch 112/300, Loss: 0.08134409384085582\n",
      "Epoch 113/300, Loss: 0.08216359580938633\n",
      "Epoch 114/300, Loss: 0.08279586640688089\n",
      "Epoch 115/300, Loss: 0.08267283640228786\n",
      "Epoch 116/300, Loss: 0.08274746858156644\n",
      "Epoch 117/300, Loss: 0.08159066564761676\n",
      "Epoch 118/300, Loss: 0.08255211894328777\n",
      "Epoch 119/300, Loss: 0.08239872008562088\n",
      "Epoch 120/300, Loss: 0.0820937529206276\n",
      "Epoch 121/300, Loss: 0.0819307674582188\n",
      "Epoch 122/300, Loss: 0.08228235978346604\n",
      "Epoch 123/300, Loss: 0.08243189178980313\n",
      "Epoch 124/300, Loss: 0.08320438346037498\n",
      "Epoch 125/300, Loss: 0.08159456344751212\n",
      "Epoch 126/300, Loss: 0.08217628242877814\n",
      "Epoch 127/300, Loss: 0.08129096145813282\n",
      "Epoch 128/300, Loss: 0.08230934521326652\n",
      "Epoch 129/300, Loss: 0.08179229899094655\n",
      "Epoch 130/300, Loss: 0.08162399868552501\n",
      "Epoch 131/300, Loss: 0.08263014543514985\n",
      "Epoch 132/300, Loss: 0.08268564481001633\n",
      "Epoch 133/300, Loss: 0.08277052583602759\n",
      "Epoch 134/300, Loss: 0.08168066694186284\n",
      "Epoch 135/300, Loss: 0.08158566229618512\n",
      "Epoch 136/300, Loss: 0.08231195635520495\n",
      "Epoch 137/300, Loss: 0.0827331027159324\n",
      "Epoch 138/300, Loss: 0.08212925837590145\n",
      "Epoch 139/300, Loss: 0.08222303482202384\n",
      "Epoch 140/300, Loss: 0.08235467683810455\n",
      "Epoch 141/300, Loss: 0.08191957783240539\n",
      "Epoch 142/300, Loss: 0.08248061514817752\n",
      "Epoch 143/300, Loss: 0.0819899457005354\n",
      "Epoch 144/300, Loss: 0.08266747972139946\n",
      "Epoch 145/300, Loss: 0.08307752357079433\n",
      "Epoch 146/300, Loss: 0.08169762904827411\n",
      "Epoch 147/300, Loss: 0.08267178386449814\n",
      "Epoch 148/300, Loss: 0.08379922004846427\n",
      "Epoch 149/300, Loss: 0.08217305288865016\n",
      "Epoch 150/300, Loss: 0.0821987442099131\n",
      "Epoch 151/300, Loss: 0.08161230499927814\n",
      "Epoch 152/300, Loss: 0.08301152116977252\n",
      "Epoch 153/300, Loss: 0.08284733157891494\n",
      "Epoch 154/300, Loss: 0.08278595942717332\n",
      "Epoch 155/300, Loss: 0.08182589595134442\n",
      "Epoch 156/300, Loss: 0.08201299034632169\n",
      "Epoch 157/300, Loss: 0.08215169608592987\n",
      "Epoch 158/300, Loss: 0.082932065312679\n",
      "Epoch 159/300, Loss: 0.08249252232221457\n",
      "Epoch 160/300, Loss: 0.08256835375840847\n",
      "Epoch 161/300, Loss: 0.0825824370751014\n",
      "Epoch 162/300, Loss: 0.08260463808591549\n",
      "Epoch 163/300, Loss: 0.08237151629649676\n",
      "Epoch 164/300, Loss: 0.08264054243381207\n",
      "Epoch 165/300, Loss: 0.08243488405759518\n",
      "Epoch 166/300, Loss: 0.08201118272084457\n",
      "Epoch 167/300, Loss: 0.08200767292426182\n",
      "Epoch 168/300, Loss: 0.08179825487045142\n",
      "Epoch 169/300, Loss: 0.08210772218612525\n",
      "Epoch 170/300, Loss: 0.08193749189376831\n",
      "Epoch 171/300, Loss: 0.0829418169764372\n",
      "Epoch 172/300, Loss: 0.08211147040128708\n",
      "Epoch 173/300, Loss: 0.08186362282587932\n",
      "Epoch 174/300, Loss: 0.08220720806947121\n",
      "Epoch 175/300, Loss: 0.08358438427631672\n",
      "Epoch 176/300, Loss: 0.08203862722103412\n",
      "Epoch 177/300, Loss: 0.08240644920330781\n",
      "Epoch 178/300, Loss: 0.08228959888219833\n",
      "Epoch 179/300, Loss: 0.08251635558330096\n",
      "Epoch 180/300, Loss: 0.08230567436951858\n",
      "Epoch 181/300, Loss: 0.08174757315562321\n",
      "Epoch 182/300, Loss: 0.0816302947126902\n",
      "Epoch 183/300, Loss: 0.08140205993102147\n",
      "Epoch 184/300, Loss: 0.08234962591758141\n",
      "Epoch 185/300, Loss: 0.08266766168750249\n",
      "Epoch 186/300, Loss: 0.08203274756669998\n",
      "Epoch 187/300, Loss: 0.08216843295555848\n",
      "Epoch 188/300, Loss: 0.08175120445398185\n",
      "Epoch 189/300, Loss: 0.08177283979379214\n",
      "Epoch 190/300, Loss: 0.0814905842909446\n",
      "Epoch 191/300, Loss: 0.08096162057839908\n",
      "Epoch 192/300, Loss: 0.08196356491400646\n",
      "Epoch 193/300, Loss: 0.08196504872578841\n",
      "Epoch 194/300, Loss: 0.08195535723979656\n",
      "Epoch 195/300, Loss: 0.08185835125354621\n",
      "Epoch 196/300, Loss: 0.08318136718410712\n",
      "Epoch 197/300, Loss: 0.08286706587442985\n",
      "Epoch 198/300, Loss: 0.0829328321493589\n",
      "Epoch 199/300, Loss: 0.08276043545741302\n",
      "Epoch 200/300, Loss: 0.08178811692274533\n",
      "Epoch 201/300, Loss: 0.0819651851287255\n",
      "Epoch 202/300, Loss: 0.08191349873175988\n",
      "Epoch 203/300, Loss: 0.08120894317443554\n",
      "Epoch 204/300, Loss: 0.0830279067158699\n",
      "Epoch 205/300, Loss: 0.08308383421255992\n",
      "Epoch 206/300, Loss: 0.08308522059367253\n",
      "Epoch 207/300, Loss: 0.08240656096201676\n",
      "Epoch 208/300, Loss: 0.08195953758863303\n",
      "Epoch 209/300, Loss: 0.08165732484597427\n",
      "Epoch 210/300, Loss: 0.08311026142193721\n",
      "Epoch 211/300, Loss: 0.08193692966149403\n",
      "Epoch 212/300, Loss: 0.08213473283327542\n",
      "Epoch 213/300, Loss: 0.08195659002432457\n",
      "Epoch 214/300, Loss: 0.08134186325164941\n",
      "Epoch 215/300, Loss: 0.08203789649101403\n",
      "Epoch 216/300, Loss: 0.08183023505485974\n",
      "Epoch 217/300, Loss: 0.08107911279568306\n",
      "Epoch 218/300, Loss: 0.08221342414617538\n",
      "Epoch 219/300, Loss: 0.08177850395441055\n",
      "Epoch 220/300, Loss: 0.08144287478465301\n",
      "Epoch 221/300, Loss: 0.08155916430629216\n",
      "Epoch 222/300, Loss: 0.0816937919992667\n",
      "Epoch 223/300, Loss: 0.08108551513690215\n",
      "Epoch 224/300, Loss: 0.08212489233567165\n",
      "Epoch 225/300, Loss: 0.08225868183832902\n",
      "Epoch 226/300, Loss: 0.08259657655770962\n",
      "Epoch 227/300, Loss: 0.0822312728716777\n",
      "Epoch 228/300, Loss: 0.08317200839519501\n",
      "Epoch 229/300, Loss: 0.08253682175507912\n",
      "Epoch 230/300, Loss: 0.08216062016212024\n",
      "Epoch 231/300, Loss: 0.0809373755294543\n",
      "Epoch 232/300, Loss: 0.0815063606087978\n",
      "Epoch 233/300, Loss: 0.08228241308377339\n",
      "Epoch 234/300, Loss: 0.08195433077903894\n",
      "Epoch 235/300, Loss: 0.08293429360939907\n",
      "Epoch 236/300, Loss: 0.0821976512670517\n",
      "Epoch 237/300, Loss: 0.08214543100733024\n",
      "Epoch 238/300, Loss: 0.08183573415646186\n",
      "Epoch 239/300, Loss: 0.08254292779243909\n",
      "Epoch 240/300, Loss: 0.08250916233429542\n",
      "Epoch 241/300, Loss: 0.08258038988480201\n",
      "Epoch 242/300, Loss: 0.08195581172521298\n",
      "Epoch 243/300, Loss: 0.08242113372454277\n",
      "Epoch 244/300, Loss: 0.08295517987929858\n",
      "Epoch 245/300, Loss: 0.08183594105335382\n",
      "Epoch 246/300, Loss: 0.08268371396339856\n",
      "Epoch 247/300, Loss: 0.08235312769046196\n",
      "Epoch 248/300, Loss: 0.08226666198326991\n",
      "Epoch 249/300, Loss: 0.0819406291613212\n",
      "Epoch 250/300, Loss: 0.08137163233298522\n",
      "Epoch 251/300, Loss: 0.08171652314754632\n",
      "Epoch 252/300, Loss: 0.08255924800267586\n",
      "Epoch 253/300, Loss: 0.08299499692825171\n",
      "Epoch 254/300, Loss: 0.0831566326893293\n",
      "Epoch 255/300, Loss: 0.0820456794821299\n",
      "Epoch 256/300, Loss: 0.0828917261499625\n",
      "Epoch 257/300, Loss: 0.08135267862906823\n",
      "Epoch 258/300, Loss: 0.08154064187636742\n",
      "Epoch 259/300, Loss: 0.08140827314211772\n",
      "Epoch 260/300, Loss: 0.08185898168728901\n",
      "Epoch 261/300, Loss: 0.08250779887804618\n",
      "Epoch 262/300, Loss: 0.08212865717135943\n",
      "Epoch 263/300, Loss: 0.08269296471889202\n",
      "Epoch 264/300, Loss: 0.08186238431013547\n",
      "Epoch 265/300, Loss: 0.08337827313404816\n",
      "Epoch 266/300, Loss: 0.08124148702392212\n",
      "Epoch 267/300, Loss: 0.08131424796122771\n",
      "Epoch 268/300, Loss: 0.08151259846412219\n",
      "Epoch 269/300, Loss: 0.08194361627101898\n",
      "Epoch 270/300, Loss: 0.08248154933636005\n",
      "Epoch 271/300, Loss: 0.0820276215672493\n",
      "Epoch 272/300, Loss: 0.08196864277124405\n",
      "Epoch 273/300, Loss: 0.08167531971748059\n",
      "Epoch 274/300, Loss: 0.08169159293174744\n",
      "Epoch 275/300, Loss: 0.08178522437810898\n",
      "Epoch 276/300, Loss: 0.08258846631416908\n",
      "Epoch 277/300, Loss: 0.08156914722460967\n",
      "Epoch 278/300, Loss: 0.08186462406928723\n",
      "Epoch 279/300, Loss: 0.08171336582073799\n",
      "Epoch 280/300, Loss: 0.08226181967900349\n",
      "Epoch 281/300, Loss: 0.08096822150624715\n",
      "Epoch 282/300, Loss: 0.08191617406331576\n",
      "Epoch 283/300, Loss: 0.0822941534794294\n",
      "Epoch 284/300, Loss: 0.08212324002614388\n",
      "Epoch 285/300, Loss: 0.081584771665243\n",
      "Epoch 286/300, Loss: 0.08154519819296323\n",
      "Epoch 287/300, Loss: 0.08233190385194925\n",
      "Epoch 288/300, Loss: 0.08110911657030766\n",
      "Epoch 289/300, Loss: 0.08158682344051507\n",
      "Epoch 290/300, Loss: 0.08090781162564571\n",
      "Epoch 291/300, Loss: 0.08300365622227009\n",
      "Epoch 292/300, Loss: 0.08290443311517055\n",
      "Epoch 293/300, Loss: 0.08195884812336701\n",
      "Epoch 294/300, Loss: 0.08262209938122676\n",
      "Epoch 295/300, Loss: 0.08205138662686715\n",
      "Epoch 296/300, Loss: 0.08194546573437177\n",
      "Epoch 297/300, Loss: 0.08206970244646072\n",
      "Epoch 298/300, Loss: 0.0814341392654639\n",
      "Epoch 299/300, Loss: 0.08231021635807477\n",
      "Epoch 300/300, Loss: 0.08243082692989936\n",
      "Average Test Loss: 0.09136322140693665\n",
      "R2 Score: -0.048157868943697446\n",
      "K-Fold Cross-Validation results: [(0.09865104034543037, -0.00294688633228235), (0.08463324047625065, -0.010798337132647662), (0.08434442803263664, -0.011895741864537346), (0.0786262433975935, -0.008944043280057379), (0.09136322140693665, -0.048157868943697446)]\n",
      "Average Loss across folds: 0.03548752961056256\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.utils.tensorboard import SummaryWriter  # For logging, adjust according to k-fold\n",
    "\n",
    "# Load dataset\n",
    "# df = pd.read_csv('AmazonDataSales_v2.csv', low_memory=False)  # Assuming CSV is in the correct path\n",
    "# Simulating dataset load with placeholder values\n",
    "df = pd.DataFrame({\n",
    "    'amount': np.random.rand(1000),\n",
    "    'category': np.random.choice(['A', 'B', 'C'], 1000),\n",
    "    'size': np.random.choice(['Small', 'Medium', 'Large'], 1000),\n",
    "    'qty': np.random.randint(1, 10, 1000),\n",
    "})\n",
    "\n",
    "# Preprocess dataset\n",
    "df_encoded = pd.get_dummies(df, columns=['category', 'size', 'qty'])\n",
    "X = df_encoded.drop('amount', axis=1).values.astype(np.float32)\n",
    "y = df['amount'].values.astype(np.float32)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X)\n",
    "y_tensor = torch.tensor(y).unsqueeze(1)  # Ensure target tensor is correctly shaped\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define model\n",
    "class FeedForwardRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2):\n",
    "        super(FeedForwardRegressor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, 1)  # Output layer for regression\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n",
    "\n",
    "# Evaluation function\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    targets_list = []\n",
    "    outputs_list = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            targets_list.append(targets.cpu().numpy())\n",
    "            outputs_list.append(outputs.cpu().numpy())\n",
    "    \n",
    "    # Concatenate all the outputs and targets to compute overall metrics\n",
    "    all_outputs = np.concatenate(outputs_list, axis=0)\n",
    "    all_targets = np.concatenate(targets_list, axis=0)\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    r2 = r2_score(all_targets, all_outputs)\n",
    "    \n",
    "    print(f'Average Test Loss: {avg_loss}')\n",
    "    print(f'R2 Score: {r2}')\n",
    "    return avg_loss, r2\n",
    "\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(X_tensor)):\n",
    "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
    "    \n",
    "    # Splitting the data for this fold\n",
    "    X_train, X_test = X_tensor[train_ids], X_tensor[test_ids]\n",
    "    y_train, y_test = y_tensor[train_ids], y_tensor[test_ids]\n",
    "    \n",
    "    # DataLoader\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=64, shuffle=False)\n",
    "    \n",
    "    # Model, Loss, Optimizer\n",
    "    input_size = X_train.shape[1]\n",
    "    model = FeedForwardRegressor(input_size, hidden_size1=2, hidden_size2=2).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Train and evaluate\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs=300)\n",
    "    avg_loss = evaluate_model(model, test_loader, criterion)\n",
    "    fold_results.append(avg_loss)\n",
    "\n",
    "# Reporting\n",
    "print(f\"K-Fold Cross-Validation results: {fold_results}\")\n",
    "print(f\"Average Loss across folds: {np.mean(fold_results)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLBIA_co_py_inlamning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
